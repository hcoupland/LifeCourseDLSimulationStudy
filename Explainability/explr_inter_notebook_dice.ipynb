{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn.metrics as skm\n",
    "import torch\n",
    "\n",
    "import fastai\n",
    "import tsai\n",
    "import copy\n",
    "import shap\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Assuming your data is in a variable 'X_trainvalid' (3D numpy array)\n",
    "\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import dice_ml\n",
    "#importlib.reload(dice_ml.explainer_interfaces.dice_pytorch)\n",
    "importlib.reload(dice_ml.explainer_interfaces.explainer_base)\n",
    "from dice_ml.utils.exception import UserConfigValidationException\n",
    "from dice_ml.explainer_interfaces.dice_pytorch import DicePyTorch\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "importlib.reload(fastai)\n",
    "importlib.reload(tsai)\n",
    "\n",
    "\n",
    "from tsai.all import *\n",
    "from tsai.data.validation import get_splits\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, ReduceLROnPlateau\n",
    "from fastai.data.transforms import Categorize\n",
    "from fastai.losses import FocalLossFlat\n",
    "from fastai.metrics import accuracy, BrierScore, F1Score, RocAucBinary, APScoreBinary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import Data_load_neat as Data_load\n",
    "import MLmodel_opt_learner_neat as MLmodel_opt_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4,suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in arguments from command line\n",
    "name = \"data_2real1bigdet\"\n",
    "model_name=\"ResNet\"\n",
    "randnum_split=3\n",
    "epochs=1\n",
    "device = 1\n",
    "filepath=\"/home/DIDE/smishra/Simulations/\"\n",
    "folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 9, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_raw = np.load(\"\".join([filepath,\"input_data/\",name, \"_X.npy\"])).astype(np.float32)\n",
    "\n",
    "\n",
    "Y_raw = np.squeeze(np.load(\"\".join([filepath,\"input_data/\",name, \"_YH.npy\"])))\n",
    "Y = Y_raw[:, np.shape(Y_raw)[1] - 1]\n",
    "\n",
    "print(X_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 93975, 1.0: 6025}) Counter({0.0: 75180, 1.0: 4820}) Counter({0.0: 18795, 1.0: 1205})\n"
     ]
    }
   ],
   "source": [
    "## Function to obtain the train/test split\n",
    "X_trainvalid, Y_trainvalid, X_test, Y_test, splits = Data_load.split_data(X=X_raw,Y=Y,randnum=randnum_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state set:3, cuda used: True\n"
     ]
    }
   ],
   "source": [
    "# Give the architecture for each model\n",
    "if model_name==\"LSTMFCN\":\n",
    "    arch=LSTM_FCNPlus\n",
    "\n",
    "if model_name==\"TCN\":\n",
    "    arch=TCN\n",
    "\n",
    "if model_name==\"XCM\":\n",
    "    arch=XCMPlus\n",
    "\n",
    "if model_name==\"ResCNN\":\n",
    "    arch=ResCNN\n",
    "\n",
    "if model_name==\"ResNet\":\n",
    "    arch=ResNetPlus\n",
    "\n",
    "if model_name==\"InceptionTime\":\n",
    "    arch=InceptionTimePlus\n",
    "\n",
    "if model_name==\"MLSTMFCN\":\n",
    "    arch=MLSTM_FCNPlus\n",
    "\n",
    "\n",
    "## Set seed\n",
    "Data_load.random_seed(randnum_split)\n",
    "\n",
    "## split out the test set\n",
    "splits_9010 = get_splits(\n",
    "        Y_trainvalid,\n",
    "        valid_size=0.1,\n",
    "        stratify=True,\n",
    "        shuffle=True,\n",
    "        test_size=0,\n",
    "        show_plot=False,\n",
    "        random_state=randnum_split\n",
    "        )\n",
    "Xtrainvalid90=X_trainvalid[splits_9010[0]]\n",
    "Ytrainvalid90=Y_trainvalid[splits_9010[0]]\n",
    "Xtrainvalid10=X_trainvalid[splits_9010[1]]\n",
    "Ytrainvalid10=Y_trainvalid[splits_9010[1]]\n",
    "\n",
    "randnum=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_results(f_model,X_test,Y_test):\n",
    "\n",
    "    valid_dl=f_model.dls.valid\n",
    "\n",
    "    # obtain probability scores, predicted values and targets\n",
    "    test_ds=valid_dl.dataset.add_test(X_test,Y_test)\n",
    "    test_dl=valid_dl.new(test_ds)\n",
    "    test_probas, test_targets,test_preds=f_model.get_preds(dl=test_dl,with_decoded=True,save_preds=None,save_targs=None)\n",
    "\n",
    "    # get the min, max and median of probability scores for each class\n",
    "    where1s=np.where(Y_test==1)\n",
    "    where0s=np.where(Y_test==0)\n",
    "    test_probasout=test_probas.numpy()\n",
    "    test_probasout=test_probasout[:,1]\n",
    "    print(\"Y equal 0:\")\n",
    "    print([min(test_probasout[where0s]),statistics.mean(test_probasout[where0s]),max(test_probasout[where0s])])\n",
    "    print(\"Y equal 1:\")\n",
    "    print([min(test_probasout[where1s]),statistics.mean(test_probasout[where1s]),max(test_probasout[where1s])])\n",
    "\n",
    "    ## get the various metrics for model fit\n",
    "    acc=skm.accuracy_score(test_targets,test_preds)\n",
    "    prec=skm.precision_score(test_targets,test_preds)\n",
    "    rec=skm.recall_score(test_targets,test_preds)\n",
    "    fone=skm.f1_score(test_targets,test_preds)\n",
    "    auc=skm.roc_auc_score(test_targets,test_preds)\n",
    "    prc=skm.average_precision_score(test_targets,test_preds)\n",
    "    print(f\"accuracy: {acc:.4f}\")\n",
    "    print(f\"precision: {prec:.4f}\")\n",
    "    print(f\"recall: {rec:.4f}\")\n",
    "    print(f\"f1: {fone:.4f}\")\n",
    "    print(f\"auc: {auc:.4f}\")\n",
    "    print(f\"prc: {prc:.4f}\")\n",
    "\n",
    "    return acc, prec, rec, fone, auc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorCategory(0.0625, device='cuda:1')\n",
      "TensorCategory(0.0625, device='cuda:1')\n",
      "TensorCategory(0.0625, device='cuda:1')\n",
      "TensorCategory(0.0625, device='cuda:1')\n",
      "TensorCategory(0., device='cuda:1')\n",
      "TensorCategory(0.0938, device='cuda:1')\n",
      "TensorCategory(0.1250, device='cuda:1')\n",
      "TensorCategory(0.0938, device='cuda:1')\n",
      "TensorCategory(0., device='cuda:1')\n",
      "TensorCategory(0.0312, device='cuda:1')\n",
      "2\n",
      "40\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop for fitting model with generic/pre-specified hyperparameters\n",
    "lr_max=1e-3\n",
    "batch_size=32\n",
    "alpha=0.5\n",
    "gamma=2\n",
    "\n",
    "colnames=[\"data\",\"model\",\"seed\",\"epochs\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"auc\",\"prc\", \"time\",\"lr_max\",\"batch_size\",\"alpha\",\"gamma\"]\n",
    "output = pd.DataFrame(columns=colnames)\n",
    "\n",
    "# Fitting the model on train/test with pre-selected hyperparameters\n",
    "# define the metrics for model fitting output\n",
    "metrics=[accuracy,F1Score(),RocAucBinary(),BrierScore(),APScoreBinary()]\n",
    "weights=torch.tensor([alpha,1-alpha], dtype=torch.float).to(device)\n",
    "\n",
    "ESPatience=2\n",
    "\n",
    "# prep the data for the model\n",
    "tfms=[None,[Categorize()]]\n",
    "dsets = TSDatasets(X_trainvalid, Y_trainvalid, tfms=tfms, splits=splits_9010,inplace=True)\n",
    "\n",
    "dls=TSDataLoaders.from_dsets(\n",
    "    dsets.train,\n",
    "    dsets.valid,\n",
    "    bs=batch_size,\n",
    "    num_workers=0,\n",
    "    device=device\n",
    "    )\n",
    "\n",
    "for i in range(10):\n",
    "    x,y = dls.one_batch()\n",
    "    print(sum(y)/len(y))\n",
    "\n",
    "print(dls.c)\n",
    "print(dls.len)\n",
    "print(dls.vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state set:1, cuda used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>brier_score_loss</th>\n",
       "      <th>average_precision_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to plot a chart\n"
     ]
    }
   ],
   "source": [
    "Data_load.random_seed2(randnum,dls=dls)\n",
    "\n",
    "model = arch(dls.vars, dls.c,dls.len)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "learn = Learner(\n",
    "    dls, \n",
    "    model, \n",
    "    metrics=metrics,\n",
    "    loss_func=FocalLossFlat(gamma=torch.tensor(gamma).to(device),weight=weights),\n",
    "    cbs=[EarlyStoppingCallback(patience=ESPatience),ReduceLROnPlateau(),ShowGraph()]\n",
    "    )\n",
    "\n",
    "learn.fit_one_cycle(epochs, lr_max)\n",
    "\n",
    "#MLmodel_opt_learner.test_results(learn,X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/250 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m query_instance \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m))  \u001b[39m# Replace with your actual 3D time series data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Load your pre-fitted tsai-based model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Replace this with your code to load the pre-fitted model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m your_tsai_model \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcpu()  \u001b[39m# Load your pre-fitted model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Initialize the custom model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m custom_model \u001b[39m=\u001b[39m CustomTSaiModel(model\u001b[39m=\u001b[39myour_tsai_model)  \u001b[39m# Replace with your tsai-based model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from tsai.all import *  # Import tsai and other related libraries\n",
    "from dice_ml.model_interfaces.pytorch_model import PyTorchModel\n",
    "from dice_ml import Dice\n",
    "\n",
    "# Define a custom model class that adheres to the DICE framework\n",
    "class CustomTSaiModel(PyTorchModel):\n",
    "    def __init__(self, model):\n",
    "        super(CustomTSaiModel, self).__init__(model)\n",
    "\n",
    "    def predict_fn(self, query_instance):\n",
    "        # Your tsai-based model's prediction logic\n",
    "        # Ensure that you can convert the query_instance into a format that your model expects\n",
    "        # Replace this with your actual prediction logic\n",
    "        # Example: return self.model.predict(query_instance)\n",
    "        return torch.tensor([0.7])  # Replace with your prediction\n",
    "\n",
    "# Define a sample query instance (3D time series data) for which you want a counterfactual\n",
    "query_instance = torch.tensor(np.random.rand(10, 5, 7))  # Replace with your actual 3D time series data\n",
    "\n",
    "# Load your pre-fitted tsai-based model\n",
    "# Replace this with your code to load the pre-fitted model\n",
    "your_tsai_model = learn.model.cpu()  # Load your pre-fitted model\n",
    "\n",
    "# Initialize the custom model\n",
    "custom_model = CustomTSaiModel(model=your_tsai_model)  # Replace with your tsai-based model\n",
    "data_interface = PyTorchDataInterface()\n",
    "dice = Dice(data_interface, model_interface=custom_model)\n",
    "\n",
    "\n",
    "# Generate a counterfactual explanation\n",
    "counterfactual = dice.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")\n",
    "\n",
    "# Print the counterfactuals\n",
    "print(\"Counterfactual Explanations:\")\n",
    "for cf in counterfactual.cf_examples:\n",
    "    print(cf.final_cfs[0])\n",
    "\n",
    "# Analyze and visualize the generated counterfactual explanations\n",
    "# Replace this with your own analysis and visualization code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 9, 7], expected input[1, 1, 360] to have 9 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m m \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39mModel(model\u001b[39m=\u001b[39mcustom_model, backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPYT\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Using method=gradient for generating counterfactuals\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m exp \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39;49mDice(d, m, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgradient\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Now you can use 'exp' to explain model predictions and assess fairness\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# For example, you can generate counterfactuals as follows:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m query_instance \u001b[39m=\u001b[39m input_3d[\u001b[39m0\u001b[39m]  \u001b[39m# Assuming you want to explain the first instance\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/dice.py:22\u001b[0m, in \u001b[0;36mDice.__init__\u001b[0;34m(self, data_interface, model_interface, method, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data_interface, model_interface, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Init method\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[39m    :param data_interface: an interface to access data related params.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    :param model_interface: an interface to access the output or gradients of a trained ML model.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m    :param method: Name of the method to use for generating counterfactuals\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecide_implementation_type(data_interface, model_interface, method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/dice.py:32\u001b[0m, in \u001b[0;36mDice.decide_implementation_type\u001b[0;34m(self, data_interface, model_interface, method, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[39mraise\u001b[39;00m UserConfigValidationException(\n\u001b[1;32m     29\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mPrivate data interface is not supported with kdtree explainer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m since kdtree explainer needs access to entire training data\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m decide(model_interface, method)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data_interface, model_interface, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/explainer_interfaces/dice_pytorch.py:36\u001b[0m, in \u001b[0;36mDicePyTorch.__init__\u001b[0;34m(self, data_interface, model_interface)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface\u001b[39m.\u001b[39mcreate_ohe_params(temp_ohe_data)\n\u001b[1;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_categorical_feature_indexes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_continuous_feature_indexes, \\\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_minx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_maxx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_precisions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface\u001b[39m.\u001b[39mget_data_params_for_gradient_dice()\n\u001b[0;32m---> 36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_output_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_num_output_nodes(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_interface\u001b[39m.\u001b[39;49mohe_encoded_feature_names))\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[39m# variables required to generate CFs - see generate_counterfactuals() for more info\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/model_interfaces/pytorch_model.py:57\u001b[0m, in \u001b[0;36mPyTorchModel.get_num_output_nodes\u001b[0;34m(self, inp_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_num_output_nodes\u001b[39m(\u001b[39mself\u001b[39m, inp_size):\n\u001b[1;32m     56\u001b[0m     temp_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, inp_size)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_output(temp_input)\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/model_interfaces/pytorch_model.py:41\u001b[0m, in \u001b[0;36mPyTorchModel.get_output\u001b[0;34m(self, input_instance, model_score, transform_data, out_tensor)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(input_instance):\n\u001b[1;32m     40\u001b[0m     input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mtransform(input_instance)\u001b[39m.\u001b[39mto_numpy())\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 41\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_tensor)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m out_tensor:\n\u001b[1;32m     43\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_3d):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Apply the original model's forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moriginal_model(input_3d)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/tsai/models/ResNetPlus.py:41\u001b[0m, in \u001b[0;36mResBlockPlus.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     40\u001b[0m     res \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 41\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvblock1(x)\n\u001b[1;32m     42\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock2(x)\n\u001b[1;32m     43\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock3(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 9, 7], expected input[1, 1, 360] to have 9 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import dice_ml\n",
    "\n",
    "# Assuming your data is in a variable 'X_trainvalid' (3D numpy array)\n",
    "\n",
    "# Define the original dimensions\n",
    "individuals, features, time_points = X_trainvalid.shape\n",
    "\n",
    "# Create a custom model that takes the 3D input data\n",
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.original_model = original_model\n",
    "\n",
    "    def forward(self, input_3d):\n",
    "        # Apply the original model's forward pass\n",
    "        output = self.original_model(input_3d)\n",
    "        return output\n",
    "\n",
    "# Instantiate the custom model using your existing model\n",
    "learn_model = learn.model.cpu()  # Assuming this is your trained model\n",
    "custom_model = CustomModel(learn_model)\n",
    "\n",
    "# Reshape the 3D input data\n",
    "input_3d = torch.tensor(X_trainvalid, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the 3D input data\n",
    "reshaped_data = input_3d.reshape((individuals, -1))\n",
    "column_names = [f\"feature_{i}_time_{j}\" for i in range(features) for j in range(time_points)]\n",
    "df = pd.DataFrame(reshaped_data.numpy(), columns=column_names)\n",
    "\n",
    "\n",
    "# Set the outcome variable (replace 'Y_trainvalid' with your actual outcome data)\n",
    "outcome_variable = Y_trainvalid\n",
    "df['resp_out'] = outcome_variable\n",
    "\n",
    "# Continue with DICE-ML for explanations and fairness assessments\n",
    "\n",
    "# Create a Dice-ML Data object using the transformed 3D data\n",
    "d = dice_ml.Data(dataframe=df,  continuous_features=[],categorical_features=df.columns.tolist()[:-1], outcome_name=\"resp_out\")\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=custom_model, backend=\"PYT\")\n",
    "\n",
    "# Using method=gradient for generating counterfactuals\n",
    "exp = dice_ml.Dice(d, m, method=\"gradient\")\n",
    "\n",
    "# Now you can use 'exp' to explain model predictions and assess fairness\n",
    "# For example, you can generate counterfactuals as follows:\n",
    "query_instance = input_3d[0]  # Assuming you want to explain the first instance\n",
    "explanation = exp.generate_counterfactuals(query_instance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the original dimensions\n",
    "individuals, features, time_points = X_trainvalid.shape\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the custom model using your existing model\n",
    "learn_model = learn.model.cpu()  # Assuming this is your trained model\n",
    "\n",
    "\n",
    "# Reshape the 3D input data\n",
    "input_3d = torch.tensor(X_trainvalid, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the 3D input data\n",
    "reshaped_data = input_3d.reshape((individuals, -1))\n",
    "column_names = [f\"feature_{i}_time_{j}\" for i in range(features) for j in range(time_points)]\n",
    "df = pd.DataFrame(reshaped_data.numpy(), columns=column_names)\n",
    "\n",
    "\n",
    "# Set the outcome variable (replace 'Y_trainvalid' with your actual outcome data)\n",
    "outcome_variable = Y_trainvalid\n",
    "df['resp_out'] = outcome_variable\n",
    "\n",
    "\n",
    "# Create a Dice-ML Data object using the transformed 3D data\n",
    "d = dice_ml.Data(dataframe=df,  continuous_features=[],categorical_features=df.columns.tolist()[:-1], outcome_name=\"resp_out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PublicData' object has no attribute 'ohe_encoded_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Using sklearn backend\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m m \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39mModel(model\u001b[39m=\u001b[39mcustom_model, backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPYT\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39mget_num_output_nodes(\u001b[39mlen\u001b[39m(d\u001b[39m.\u001b[39;49mohe_encoded_feature_names))\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Using method=gradient for generating counterfactuals\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m exp \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39mDice(d, m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgradient\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PublicData' object has no attribute 'ohe_encoded_feature_names'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a custom model that takes the 3D input data\n",
    "# class CustomModel(torch.nn.Module):\n",
    "#     def __init__(self, original_model):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.original_model = original_model\n",
    "\n",
    "#     def forward(self, input_3d):\n",
    "#         # Apply the original model's forward pass\n",
    "#         output = self.original_model(input_3d)\n",
    "#         return output\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, original_model, features, time_points):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.features = features\n",
    "        self.time_points = time_points\n",
    "        self.original_model = original_model\n",
    "        self.reshape_layer = nn.Flatten()  # This layer will reshape the input\n",
    "\n",
    "    def forward(self, input_2d):\n",
    "        # Reshape the 2D input to 3D format\n",
    "        reshaped_data = input_2d.view(-1, self.features, self.time_points)\n",
    "        # Apply the reshape layer\n",
    "        reshaped_data = self.reshape_layer(reshaped_data)\n",
    "        # Expand the input to match the expected number of channels\n",
    "        reshaped_data = reshaped_data.unsqueeze(1).repeat(1, 9, 1)\n",
    "        # Apply the original model's forward pass\n",
    "        output = self.original_model(reshaped_data)\n",
    "\n",
    "        return output[:,0].unsqueeze(0)\n",
    "    \n",
    "\n",
    "#custom_model = CustomModel(learn_model)\n",
    "custom_model = CustomModel(learn.model, features, time_points)\n",
    "\n",
    "\n",
    "\n",
    "# Continue with DICE-ML for explanations and fairness assessments\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=custom_model, backend=\"PYT\")\n",
    "\n",
    "\n",
    "# Using method=gradient for generating counterfactuals\n",
    "exp = dice_ml.Dice(d, m, method=\"gradient\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.get_num_output_nodes(len(d.ohe_encoded_feature_names)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_num_output_nodes(len(d.ohe_encoded_feature_names)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_instance = df.iloc[0, :-1].to_dict()\n",
    "query_instance = df.iloc[0:1, :-1]#.to_dict()\n",
    "#query_instance_np = np.array([list(query_instance.values())])\n",
    "\n",
    "#explanation = exp.generate_counterfactuals(query_instance, total_CFs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0_time_0</th>\n",
       "      <th>feature_0_time_1</th>\n",
       "      <th>feature_0_time_2</th>\n",
       "      <th>feature_0_time_3</th>\n",
       "      <th>feature_0_time_4</th>\n",
       "      <th>feature_0_time_5</th>\n",
       "      <th>feature_0_time_6</th>\n",
       "      <th>feature_0_time_7</th>\n",
       "      <th>feature_0_time_8</th>\n",
       "      <th>feature_0_time_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_8_time_30</th>\n",
       "      <th>feature_8_time_31</th>\n",
       "      <th>feature_8_time_32</th>\n",
       "      <th>feature_8_time_33</th>\n",
       "      <th>feature_8_time_34</th>\n",
       "      <th>feature_8_time_35</th>\n",
       "      <th>feature_8_time_36</th>\n",
       "      <th>feature_8_time_37</th>\n",
       "      <th>feature_8_time_38</th>\n",
       "      <th>feature_8_time_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0_time_0  feature_0_time_1  feature_0_time_2  feature_0_time_3  \\\n",
       "0               1.0               1.0               1.0               1.0   \n",
       "\n",
       "   feature_0_time_4  feature_0_time_5  feature_0_time_6  feature_0_time_7  \\\n",
       "0               1.0               1.0               1.0               1.0   \n",
       "\n",
       "   feature_0_time_8  feature_0_time_9  ...  feature_8_time_30  \\\n",
       "0               1.0               1.0  ...                0.0   \n",
       "\n",
       "   feature_8_time_31  feature_8_time_32  feature_8_time_33  feature_8_time_34  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   feature_8_time_35  feature_8_time_36  feature_8_time_37  feature_8_time_38  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   feature_8_time_39  \n",
       "0                1.0  \n",
       "\n",
       "[1 rows x 360 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_instance = {k: str(int(v)) for (k, v) in query_instance.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m query_instance2\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mSeries(query_instance)\u001b[39m.\u001b[39mto_frame()\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/pandas/core/series.py:355\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     name \u001b[39m=\u001b[39m ibase\u001b[39m.\u001b[39mmaybe_extract_name(name, data, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mif\u001b[39;00m is_empty_data(data) \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m         \u001b[39m# gh-17261\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    358\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe default dtype for empty Series will be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a future version. Specify a dtype explicitly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    363\u001b[0m         )\n\u001b[1;32m    364\u001b[0m         \u001b[39m# uncomment the line below when removing the DeprecationWarning\u001b[39;00m\n\u001b[1;32m    365\u001b[0m         \u001b[39m# dtype = np.dtype(object)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/pandas/core/construction.py:796\u001b[0m, in \u001b[0;36mis_empty_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    794\u001b[0m is_none \u001b[39m=\u001b[39m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m is_list_like_without_dtype \u001b[39m=\u001b[39m is_list_like(data) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 796\u001b[0m is_simple_empty \u001b[39m=\u001b[39m is_list_like_without_dtype \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;49;00m data\n\u001b[1;32m    797\u001b[0m \u001b[39mreturn\u001b[39;00m is_none \u001b[39mor\u001b[39;00m is_simple_empty\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/pandas/core/generic.py:1537\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 1537\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1538\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1540\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "query_instance2=pd.Series(query_instance).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_torch; line 422; query instance shape(1, 360)\n",
      "dice_torch; line 423; query instance shape(360,)\n",
      "dice_torch; line 424; tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "line 149, input instance = tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "line 140 dice_Pytorch, nodes thing = 1\n",
      "line 141 dice_pytorch; self model thing = <dice_ml.model_interfaces.pytorch_model.PyTorchModel object at 0x7fb231d49f40>\n",
      "line 142 dice_pytorch; id thing = 140403316924224\n",
      " line 150, output = []\n",
      "line 140 dice_Pytorch, nodes thing = 1\n",
      "line 141 dice_pytorch; self model thing = <dice_ml.model_interfaces.pytorch_model.PyTorchModel object at 0x7fb231d49f40>\n",
      "line 142 dice_pytorch; id thing = 140403316924224\n",
      "dice_torch; line 424; []\n",
      "line 149, input instance = tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "line 140 dice_Pytorch, nodes thing = 1\n",
      "line 141 dice_pytorch; self model thing = <dice_ml.model_interfaces.pytorch_model.PyTorchModel object at 0x7fb231d49f40>\n",
      "line 142 dice_pytorch; id thing = 140403316924224\n",
      " line 150, output = []\n",
      "line 140 dice_Pytorch, nodes thing = 1\n",
      "line 141 dice_pytorch; self model thing = <dice_ml.model_interfaces.pytorch_model.PyTorchModel object at 0x7fb231d49f40>\n",
      "line 142 dice_pytorch; id thing = 140403316924224\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#explanation = exp.generate_counterfactuals(query_instance_np, total_CFs=1, desired_class=\"opposite\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwpia-dide148/home/DIDE/smishra/Simulations/Simulations/explr_inter_notebook_dice.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m explanation \u001b[39m=\u001b[39m exp\u001b[39m.\u001b[39;49mgenerate_counterfactuals(query_instance, total_CFs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, desired_class\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mopposite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/explainer_interfaces/explainer_base.py:161\u001b[0m, in \u001b[0;36mExplainerBase.generate_counterfactuals\u001b[0;34m(self, query_instances, total_CFs, desired_class, desired_range, permitted_range, features_to_vary, stopping_threshold, posthoc_sparsity_param, proximity_weight, sparsity_weight, diversity_weight, categorical_penalty, posthoc_sparsity_algorithm, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m query_instance \u001b[39min\u001b[39;00m tqdm(query_instances_list):\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface\u001b[39m.\u001b[39mset_continuous_feature_indexes(query_instance)\n\u001b[0;32m--> 161\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_counterfactuals(\n\u001b[1;32m    162\u001b[0m         query_instance, total_CFs,\n\u001b[1;32m    163\u001b[0m         desired_class\u001b[39m=\u001b[39;49mdesired_class,\n\u001b[1;32m    164\u001b[0m         desired_range\u001b[39m=\u001b[39;49mdesired_range,\n\u001b[1;32m    165\u001b[0m         permitted_range\u001b[39m=\u001b[39;49mpermitted_range,\n\u001b[1;32m    166\u001b[0m         features_to_vary\u001b[39m=\u001b[39;49mfeatures_to_vary,\n\u001b[1;32m    167\u001b[0m         stopping_threshold\u001b[39m=\u001b[39;49mstopping_threshold,\n\u001b[1;32m    168\u001b[0m         posthoc_sparsity_param\u001b[39m=\u001b[39;49mposthoc_sparsity_param,\n\u001b[1;32m    169\u001b[0m         posthoc_sparsity_algorithm\u001b[39m=\u001b[39;49mposthoc_sparsity_algorithm,\n\u001b[1;32m    170\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    171\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    172\u001b[0m     cf_examples_arr\u001b[39m.\u001b[39mappend(res)\n\u001b[1;32m    173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_any_counterfactuals_computed(cf_examples_arr\u001b[39m=\u001b[39mcf_examples_arr)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/explainer_interfaces/dice_pytorch.py:123\u001b[0m, in \u001b[0;36mDicePyTorch._generate_counterfactuals\u001b[0;34m(self, query_instance, total_CFs, desired_class, desired_range, proximity_weight, diversity_weight, categorical_penalty, algorithm, features_to_vary, permitted_range, yloss_type, diversity_loss_type, feature_weights, optimizer, learning_rate, min_iter, max_iter, project_iter, loss_diff_thres, loss_converge_maxiter, verbose, init_near_query_instance, tie_random, stopping_threshold, posthoc_sparsity_param, posthoc_sparsity_algorithm, limit_steps_ls)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m [proximity_weight, diversity_weight, categorical_penalty] \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameters:\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_hyperparameters(proximity_weight, diversity_weight, categorical_penalty)\n\u001b[1;32m    122\u001b[0m final_cfs_df, test_instance_df, final_cfs_df_sparse \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_counterfactuals(\n\u001b[1;32m    124\u001b[0m         query_instance, desired_class, optimizer, learning_rate, min_iter, max_iter,\n\u001b[1;32m    125\u001b[0m         project_iter, loss_diff_thres, loss_converge_maxiter, verbose, init_near_query_instance,\n\u001b[1;32m    126\u001b[0m         tie_random, stopping_threshold, posthoc_sparsity_param, posthoc_sparsity_algorithm, limit_steps_ls)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m exp\u001b[39m.\u001b[39mCounterfactualExamples(\n\u001b[1;32m    129\u001b[0m     data_interface\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface,\n\u001b[1;32m    130\u001b[0m     final_cfs_df\u001b[39m=\u001b[39mfinal_cfs_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     posthoc_sparsity_param\u001b[39m=\u001b[39mposthoc_sparsity_param,\n\u001b[1;32m    134\u001b[0m     desired_class\u001b[39m=\u001b[39mdesired_class)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/explainer_interfaces/dice_pytorch.py:443\u001b[0m, in \u001b[0;36mDicePyTorch.find_counterfactuals\u001b[0;34m(self, query_instance, desired_class, optimizer, learning_rate, min_iter, max_iter, project_iter, loss_diff_thres, loss_converge_maxiter, verbose, init_near_query_instance, tie_random, stopping_threshold, posthoc_sparsity_param, posthoc_sparsity_algorithm, limit_steps_ls)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdice_torch; line 424; \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_fn(torch\u001b[39m.\u001b[39mtensor(query_instance)\u001b[39m.\u001b[39mfloat())\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    441\u001b[0m \u001b[39m### Helen stop messing around\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[39m# find the predicted value of query_instance\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m test_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_fn(torch\u001b[39m.\u001b[39;49mtensor(query_instance)\u001b[39m.\u001b[39;49mfloat())[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m desired_class \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mopposite\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    445\u001b[0m     desired_class \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mround(test_pred)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "#explanation = exp.generate_counterfactuals(query_instance_np, total_CFs=1, desired_class=\"opposite\")\n",
    "explanation = exp.generate_counterfactuals(query_instance, total_CFs=2, desired_class=\"opposite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140403316924224"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming your data is in a variable 'data'\n",
    "individuals, features, time_points = X_trainvalid.shape\n",
    "reshaped_data = X_trainvalid.reshape((individuals, features * time_points))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [f\"feature_{i}_time_{j}\" for i in range(features) for j in range(time_points)]\n",
    "df = pd.DataFrame(reshaped_data, columns=column_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_instance2=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
    "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([360])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_instance2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_instance=m.transformer.transform(query_instance).to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1993, -1.0457]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_output(torch.tensor(input_instance).float(), transform_data=False, out_tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "m.get_output(torch.tensor(input_instance2).float(), transform_data=False, out_tensor=False)[(2-1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.0457], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_output(torch.tensor(input_instance2).float(), transform_data=False, out_tensor=False)[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([360])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(input_instance2).float().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classifier'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_0_time_0     1.0\n",
       "feature_0_time_1     1.0\n",
       "feature_0_time_2     1.0\n",
       "feature_0_time_3     1.0\n",
       "feature_0_time_4     1.0\n",
       "                    ... \n",
       "feature_8_time_35    0.0\n",
       "feature_8_time_36    0.0\n",
       "feature_8_time_37    0.0\n",
       "feature_8_time_38    0.0\n",
       "feature_8_time_39    1.0\n",
       "Length: 360, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(query_instance).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_0_time_0': '1',\n",
       " 'feature_0_time_1': '1',\n",
       " 'feature_0_time_2': '1',\n",
       " 'feature_0_time_3': '1',\n",
       " 'feature_0_time_4': '1',\n",
       " 'feature_0_time_5': '1',\n",
       " 'feature_0_time_6': '1',\n",
       " 'feature_0_time_7': '1',\n",
       " 'feature_0_time_8': '1',\n",
       " 'feature_0_time_9': '1',\n",
       " 'feature_0_time_10': '1',\n",
       " 'feature_0_time_11': '1',\n",
       " 'feature_0_time_12': '1',\n",
       " 'feature_0_time_13': '1',\n",
       " 'feature_0_time_14': '1',\n",
       " 'feature_0_time_15': '1',\n",
       " 'feature_0_time_16': '1',\n",
       " 'feature_0_time_17': '1',\n",
       " 'feature_0_time_18': '1',\n",
       " 'feature_0_time_19': '1',\n",
       " 'feature_0_time_20': '1',\n",
       " 'feature_0_time_21': '1',\n",
       " 'feature_0_time_22': '1',\n",
       " 'feature_0_time_23': '1',\n",
       " 'feature_0_time_24': '1',\n",
       " 'feature_0_time_25': '1',\n",
       " 'feature_0_time_26': '1',\n",
       " 'feature_0_time_27': '1',\n",
       " 'feature_0_time_28': '1',\n",
       " 'feature_0_time_29': '1',\n",
       " 'feature_0_time_30': '1',\n",
       " 'feature_0_time_31': '1',\n",
       " 'feature_0_time_32': '1',\n",
       " 'feature_0_time_33': '1',\n",
       " 'feature_0_time_34': '1',\n",
       " 'feature_0_time_35': '1',\n",
       " 'feature_0_time_36': '1',\n",
       " 'feature_0_time_37': '1',\n",
       " 'feature_0_time_38': '1',\n",
       " 'feature_0_time_39': '1',\n",
       " 'feature_1_time_0': '0',\n",
       " 'feature_1_time_1': '0',\n",
       " 'feature_1_time_2': '0',\n",
       " 'feature_1_time_3': '0',\n",
       " 'feature_1_time_4': '0',\n",
       " 'feature_1_time_5': '0',\n",
       " 'feature_1_time_6': '0',\n",
       " 'feature_1_time_7': '0',\n",
       " 'feature_1_time_8': '0',\n",
       " 'feature_1_time_9': '0',\n",
       " 'feature_1_time_10': '0',\n",
       " 'feature_1_time_11': '0',\n",
       " 'feature_1_time_12': '0',\n",
       " 'feature_1_time_13': '0',\n",
       " 'feature_1_time_14': '0',\n",
       " 'feature_1_time_15': '0',\n",
       " 'feature_1_time_16': '0',\n",
       " 'feature_1_time_17': '0',\n",
       " 'feature_1_time_18': '0',\n",
       " 'feature_1_time_19': '0',\n",
       " 'feature_1_time_20': '0',\n",
       " 'feature_1_time_21': '0',\n",
       " 'feature_1_time_22': '0',\n",
       " 'feature_1_time_23': '0',\n",
       " 'feature_1_time_24': '0',\n",
       " 'feature_1_time_25': '0',\n",
       " 'feature_1_time_26': '0',\n",
       " 'feature_1_time_27': '0',\n",
       " 'feature_1_time_28': '0',\n",
       " 'feature_1_time_29': '0',\n",
       " 'feature_1_time_30': '0',\n",
       " 'feature_1_time_31': '0',\n",
       " 'feature_1_time_32': '0',\n",
       " 'feature_1_time_33': '0',\n",
       " 'feature_1_time_34': '0',\n",
       " 'feature_1_time_35': '0',\n",
       " 'feature_1_time_36': '0',\n",
       " 'feature_1_time_37': '0',\n",
       " 'feature_1_time_38': '0',\n",
       " 'feature_1_time_39': '0',\n",
       " 'feature_2_time_0': '0',\n",
       " 'feature_2_time_1': '0',\n",
       " 'feature_2_time_2': '0',\n",
       " 'feature_2_time_3': '0',\n",
       " 'feature_2_time_4': '0',\n",
       " 'feature_2_time_5': '0',\n",
       " 'feature_2_time_6': '0',\n",
       " 'feature_2_time_7': '0',\n",
       " 'feature_2_time_8': '0',\n",
       " 'feature_2_time_9': '0',\n",
       " 'feature_2_time_10': '0',\n",
       " 'feature_2_time_11': '0',\n",
       " 'feature_2_time_12': '0',\n",
       " 'feature_2_time_13': '0',\n",
       " 'feature_2_time_14': '0',\n",
       " 'feature_2_time_15': '0',\n",
       " 'feature_2_time_16': '0',\n",
       " 'feature_2_time_17': '0',\n",
       " 'feature_2_time_18': '0',\n",
       " 'feature_2_time_19': '0',\n",
       " 'feature_2_time_20': '0',\n",
       " 'feature_2_time_21': '0',\n",
       " 'feature_2_time_22': '0',\n",
       " 'feature_2_time_23': '0',\n",
       " 'feature_2_time_24': '0',\n",
       " 'feature_2_time_25': '0',\n",
       " 'feature_2_time_26': '0',\n",
       " 'feature_2_time_27': '0',\n",
       " 'feature_2_time_28': '0',\n",
       " 'feature_2_time_29': '0',\n",
       " 'feature_2_time_30': '0',\n",
       " 'feature_2_time_31': '0',\n",
       " 'feature_2_time_32': '0',\n",
       " 'feature_2_time_33': '0',\n",
       " 'feature_2_time_34': '0',\n",
       " 'feature_2_time_35': '0',\n",
       " 'feature_2_time_36': '0',\n",
       " 'feature_2_time_37': '0',\n",
       " 'feature_2_time_38': '0',\n",
       " 'feature_2_time_39': '0',\n",
       " 'feature_3_time_0': '0',\n",
       " 'feature_3_time_1': '0',\n",
       " 'feature_3_time_2': '0',\n",
       " 'feature_3_time_3': '0',\n",
       " 'feature_3_time_4': '0',\n",
       " 'feature_3_time_5': '0',\n",
       " 'feature_3_time_6': '0',\n",
       " 'feature_3_time_7': '0',\n",
       " 'feature_3_time_8': '0',\n",
       " 'feature_3_time_9': '0',\n",
       " 'feature_3_time_10': '0',\n",
       " 'feature_3_time_11': '0',\n",
       " 'feature_3_time_12': '0',\n",
       " 'feature_3_time_13': '0',\n",
       " 'feature_3_time_14': '0',\n",
       " 'feature_3_time_15': '0',\n",
       " 'feature_3_time_16': '0',\n",
       " 'feature_3_time_17': '0',\n",
       " 'feature_3_time_18': '0',\n",
       " 'feature_3_time_19': '0',\n",
       " 'feature_3_time_20': '0',\n",
       " 'feature_3_time_21': '0',\n",
       " 'feature_3_time_22': '0',\n",
       " 'feature_3_time_23': '0',\n",
       " 'feature_3_time_24': '0',\n",
       " 'feature_3_time_25': '0',\n",
       " 'feature_3_time_26': '0',\n",
       " 'feature_3_time_27': '0',\n",
       " 'feature_3_time_28': '0',\n",
       " 'feature_3_time_29': '0',\n",
       " 'feature_3_time_30': '0',\n",
       " 'feature_3_time_31': '0',\n",
       " 'feature_3_time_32': '0',\n",
       " 'feature_3_time_33': '0',\n",
       " 'feature_3_time_34': '0',\n",
       " 'feature_3_time_35': '0',\n",
       " 'feature_3_time_36': '0',\n",
       " 'feature_3_time_37': '0',\n",
       " 'feature_3_time_38': '0',\n",
       " 'feature_3_time_39': '0',\n",
       " 'feature_4_time_0': '0',\n",
       " 'feature_4_time_1': '0',\n",
       " 'feature_4_time_2': '0',\n",
       " 'feature_4_time_3': '0',\n",
       " 'feature_4_time_4': '0',\n",
       " 'feature_4_time_5': '0',\n",
       " 'feature_4_time_6': '0',\n",
       " 'feature_4_time_7': '0',\n",
       " 'feature_4_time_8': '0',\n",
       " 'feature_4_time_9': '0',\n",
       " 'feature_4_time_10': '0',\n",
       " 'feature_4_time_11': '0',\n",
       " 'feature_4_time_12': '0',\n",
       " 'feature_4_time_13': '0',\n",
       " 'feature_4_time_14': '0',\n",
       " 'feature_4_time_15': '0',\n",
       " 'feature_4_time_16': '0',\n",
       " 'feature_4_time_17': '0',\n",
       " 'feature_4_time_18': '0',\n",
       " 'feature_4_time_19': '0',\n",
       " 'feature_4_time_20': '0',\n",
       " 'feature_4_time_21': '0',\n",
       " 'feature_4_time_22': '0',\n",
       " 'feature_4_time_23': '0',\n",
       " 'feature_4_time_24': '0',\n",
       " 'feature_4_time_25': '0',\n",
       " 'feature_4_time_26': '0',\n",
       " 'feature_4_time_27': '0',\n",
       " 'feature_4_time_28': '0',\n",
       " 'feature_4_time_29': '0',\n",
       " 'feature_4_time_30': '0',\n",
       " 'feature_4_time_31': '0',\n",
       " 'feature_4_time_32': '0',\n",
       " 'feature_4_time_33': '0',\n",
       " 'feature_4_time_34': '0',\n",
       " 'feature_4_time_35': '0',\n",
       " 'feature_4_time_36': '0',\n",
       " 'feature_4_time_37': '0',\n",
       " 'feature_4_time_38': '0',\n",
       " 'feature_4_time_39': '0',\n",
       " 'feature_5_time_0': '1',\n",
       " 'feature_5_time_1': '0',\n",
       " 'feature_5_time_2': '0',\n",
       " 'feature_5_time_3': '0',\n",
       " 'feature_5_time_4': '0',\n",
       " 'feature_5_time_5': '0',\n",
       " 'feature_5_time_6': '0',\n",
       " 'feature_5_time_7': '0',\n",
       " 'feature_5_time_8': '0',\n",
       " 'feature_5_time_9': '0',\n",
       " 'feature_5_time_10': '0',\n",
       " 'feature_5_time_11': '0',\n",
       " 'feature_5_time_12': '0',\n",
       " 'feature_5_time_13': '0',\n",
       " 'feature_5_time_14': '0',\n",
       " 'feature_5_time_15': '0',\n",
       " 'feature_5_time_16': '0',\n",
       " 'feature_5_time_17': '0',\n",
       " 'feature_5_time_18': '0',\n",
       " 'feature_5_time_19': '0',\n",
       " 'feature_5_time_20': '0',\n",
       " 'feature_5_time_21': '0',\n",
       " 'feature_5_time_22': '0',\n",
       " 'feature_5_time_23': '0',\n",
       " 'feature_5_time_24': '0',\n",
       " 'feature_5_time_25': '0',\n",
       " 'feature_5_time_26': '0',\n",
       " 'feature_5_time_27': '0',\n",
       " 'feature_5_time_28': '0',\n",
       " 'feature_5_time_29': '1',\n",
       " 'feature_5_time_30': '0',\n",
       " 'feature_5_time_31': '0',\n",
       " 'feature_5_time_32': '0',\n",
       " 'feature_5_time_33': '0',\n",
       " 'feature_5_time_34': '0',\n",
       " 'feature_5_time_35': '0',\n",
       " 'feature_5_time_36': '0',\n",
       " 'feature_5_time_37': '0',\n",
       " 'feature_5_time_38': '0',\n",
       " 'feature_5_time_39': '0',\n",
       " 'feature_6_time_0': '0',\n",
       " 'feature_6_time_1': '0',\n",
       " 'feature_6_time_2': '0',\n",
       " 'feature_6_time_3': '0',\n",
       " 'feature_6_time_4': '0',\n",
       " 'feature_6_time_5': '0',\n",
       " 'feature_6_time_6': '0',\n",
       " 'feature_6_time_7': '0',\n",
       " 'feature_6_time_8': '0',\n",
       " 'feature_6_time_9': '0',\n",
       " 'feature_6_time_10': '0',\n",
       " 'feature_6_time_11': '0',\n",
       " 'feature_6_time_12': '0',\n",
       " 'feature_6_time_13': '0',\n",
       " 'feature_6_time_14': '0',\n",
       " 'feature_6_time_15': '0',\n",
       " 'feature_6_time_16': '0',\n",
       " 'feature_6_time_17': '0',\n",
       " 'feature_6_time_18': '1',\n",
       " 'feature_6_time_19': '0',\n",
       " 'feature_6_time_20': '0',\n",
       " 'feature_6_time_21': '1',\n",
       " 'feature_6_time_22': '0',\n",
       " 'feature_6_time_23': '0',\n",
       " 'feature_6_time_24': '1',\n",
       " 'feature_6_time_25': '0',\n",
       " 'feature_6_time_26': '0',\n",
       " 'feature_6_time_27': '0',\n",
       " 'feature_6_time_28': '0',\n",
       " 'feature_6_time_29': '0',\n",
       " 'feature_6_time_30': '0',\n",
       " 'feature_6_time_31': '0',\n",
       " 'feature_6_time_32': '0',\n",
       " 'feature_6_time_33': '0',\n",
       " 'feature_6_time_34': '0',\n",
       " 'feature_6_time_35': '0',\n",
       " 'feature_6_time_36': '0',\n",
       " 'feature_6_time_37': '0',\n",
       " 'feature_6_time_38': '0',\n",
       " 'feature_6_time_39': '0',\n",
       " 'feature_7_time_0': '0',\n",
       " 'feature_7_time_1': '0',\n",
       " 'feature_7_time_2': '0',\n",
       " 'feature_7_time_3': '0',\n",
       " 'feature_7_time_4': '0',\n",
       " 'feature_7_time_5': '0',\n",
       " 'feature_7_time_6': '0',\n",
       " 'feature_7_time_7': '0',\n",
       " 'feature_7_time_8': '0',\n",
       " 'feature_7_time_9': '0',\n",
       " 'feature_7_time_10': '0',\n",
       " 'feature_7_time_11': '0',\n",
       " 'feature_7_time_12': '0',\n",
       " 'feature_7_time_13': '0',\n",
       " 'feature_7_time_14': '0',\n",
       " 'feature_7_time_15': '0',\n",
       " 'feature_7_time_16': '0',\n",
       " 'feature_7_time_17': '0',\n",
       " 'feature_7_time_18': '0',\n",
       " 'feature_7_time_19': '0',\n",
       " 'feature_7_time_20': '0',\n",
       " 'feature_7_time_21': '0',\n",
       " 'feature_7_time_22': '0',\n",
       " 'feature_7_time_23': '0',\n",
       " 'feature_7_time_24': '0',\n",
       " 'feature_7_time_25': '0',\n",
       " 'feature_7_time_26': '0',\n",
       " 'feature_7_time_27': '0',\n",
       " 'feature_7_time_28': '0',\n",
       " 'feature_7_time_29': '0',\n",
       " 'feature_7_time_30': '0',\n",
       " 'feature_7_time_31': '0',\n",
       " 'feature_7_time_32': '0',\n",
       " 'feature_7_time_33': '0',\n",
       " 'feature_7_time_34': '0',\n",
       " 'feature_7_time_35': '0',\n",
       " 'feature_7_time_36': '0',\n",
       " 'feature_7_time_37': '0',\n",
       " 'feature_7_time_38': '0',\n",
       " 'feature_7_time_39': '0',\n",
       " 'feature_8_time_0': '0',\n",
       " 'feature_8_time_1': '0',\n",
       " 'feature_8_time_2': '1',\n",
       " 'feature_8_time_3': '0',\n",
       " 'feature_8_time_4': '0',\n",
       " 'feature_8_time_5': '0',\n",
       " 'feature_8_time_6': '0',\n",
       " 'feature_8_time_7': '1',\n",
       " 'feature_8_time_8': '0',\n",
       " 'feature_8_time_9': '0',\n",
       " 'feature_8_time_10': '0',\n",
       " 'feature_8_time_11': '0',\n",
       " 'feature_8_time_12': '0',\n",
       " 'feature_8_time_13': '0',\n",
       " 'feature_8_time_14': '0',\n",
       " 'feature_8_time_15': '0',\n",
       " 'feature_8_time_16': '0',\n",
       " 'feature_8_time_17': '1',\n",
       " 'feature_8_time_18': '0',\n",
       " 'feature_8_time_19': '0',\n",
       " 'feature_8_time_20': '0',\n",
       " 'feature_8_time_21': '0',\n",
       " 'feature_8_time_22': '0',\n",
       " 'feature_8_time_23': '0',\n",
       " 'feature_8_time_24': '0',\n",
       " 'feature_8_time_25': '0',\n",
       " 'feature_8_time_26': '0',\n",
       " 'feature_8_time_27': '0',\n",
       " 'feature_8_time_28': '0',\n",
       " 'feature_8_time_29': '0',\n",
       " 'feature_8_time_30': '0',\n",
       " 'feature_8_time_31': '0',\n",
       " 'feature_8_time_32': '0',\n",
       " 'feature_8_time_33': '0',\n",
       " 'feature_8_time_34': '0',\n",
       " 'feature_8_time_35': '0',\n",
       " 'feature_8_time_36': '0',\n",
       " 'feature_8_time_37': '0',\n",
       " 'feature_8_time_38': '0',\n",
       " 'feature_8_time_39': '1'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: str(int(v)) for (k, v) in query_instance.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_variable = Y_trainvalid  # Replace with your actual outcome data\n",
    "df['resp_out'] = outcome_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0_time_0',\n",
       " 'feature_0_time_1',\n",
       " 'feature_0_time_2',\n",
       " 'feature_0_time_3',\n",
       " 'feature_0_time_4',\n",
       " 'feature_0_time_5',\n",
       " 'feature_0_time_6',\n",
       " 'feature_0_time_7',\n",
       " 'feature_0_time_8',\n",
       " 'feature_0_time_9',\n",
       " 'feature_0_time_10',\n",
       " 'feature_0_time_11',\n",
       " 'feature_0_time_12',\n",
       " 'feature_0_time_13',\n",
       " 'feature_0_time_14',\n",
       " 'feature_0_time_15',\n",
       " 'feature_0_time_16',\n",
       " 'feature_0_time_17',\n",
       " 'feature_0_time_18',\n",
       " 'feature_0_time_19',\n",
       " 'feature_0_time_20',\n",
       " 'feature_0_time_21',\n",
       " 'feature_0_time_22',\n",
       " 'feature_0_time_23',\n",
       " 'feature_0_time_24',\n",
       " 'feature_0_time_25',\n",
       " 'feature_0_time_26',\n",
       " 'feature_0_time_27',\n",
       " 'feature_0_time_28',\n",
       " 'feature_0_time_29',\n",
       " 'feature_0_time_30',\n",
       " 'feature_0_time_31',\n",
       " 'feature_0_time_32',\n",
       " 'feature_0_time_33',\n",
       " 'feature_0_time_34',\n",
       " 'feature_0_time_35',\n",
       " 'feature_0_time_36',\n",
       " 'feature_0_time_37',\n",
       " 'feature_0_time_38',\n",
       " 'feature_0_time_39',\n",
       " 'feature_1_time_0',\n",
       " 'feature_1_time_1',\n",
       " 'feature_1_time_2',\n",
       " 'feature_1_time_3',\n",
       " 'feature_1_time_4',\n",
       " 'feature_1_time_5',\n",
       " 'feature_1_time_6',\n",
       " 'feature_1_time_7',\n",
       " 'feature_1_time_8',\n",
       " 'feature_1_time_9',\n",
       " 'feature_1_time_10',\n",
       " 'feature_1_time_11',\n",
       " 'feature_1_time_12',\n",
       " 'feature_1_time_13',\n",
       " 'feature_1_time_14',\n",
       " 'feature_1_time_15',\n",
       " 'feature_1_time_16',\n",
       " 'feature_1_time_17',\n",
       " 'feature_1_time_18',\n",
       " 'feature_1_time_19',\n",
       " 'feature_1_time_20',\n",
       " 'feature_1_time_21',\n",
       " 'feature_1_time_22',\n",
       " 'feature_1_time_23',\n",
       " 'feature_1_time_24',\n",
       " 'feature_1_time_25',\n",
       " 'feature_1_time_26',\n",
       " 'feature_1_time_27',\n",
       " 'feature_1_time_28',\n",
       " 'feature_1_time_29',\n",
       " 'feature_1_time_30',\n",
       " 'feature_1_time_31',\n",
       " 'feature_1_time_32',\n",
       " 'feature_1_time_33',\n",
       " 'feature_1_time_34',\n",
       " 'feature_1_time_35',\n",
       " 'feature_1_time_36',\n",
       " 'feature_1_time_37',\n",
       " 'feature_1_time_38',\n",
       " 'feature_1_time_39',\n",
       " 'feature_2_time_0',\n",
       " 'feature_2_time_1',\n",
       " 'feature_2_time_2',\n",
       " 'feature_2_time_3',\n",
       " 'feature_2_time_4',\n",
       " 'feature_2_time_5',\n",
       " 'feature_2_time_6',\n",
       " 'feature_2_time_7',\n",
       " 'feature_2_time_8',\n",
       " 'feature_2_time_9',\n",
       " 'feature_2_time_10',\n",
       " 'feature_2_time_11',\n",
       " 'feature_2_time_12',\n",
       " 'feature_2_time_13',\n",
       " 'feature_2_time_14',\n",
       " 'feature_2_time_15',\n",
       " 'feature_2_time_16',\n",
       " 'feature_2_time_17',\n",
       " 'feature_2_time_18',\n",
       " 'feature_2_time_19',\n",
       " 'feature_2_time_20',\n",
       " 'feature_2_time_21',\n",
       " 'feature_2_time_22',\n",
       " 'feature_2_time_23',\n",
       " 'feature_2_time_24',\n",
       " 'feature_2_time_25',\n",
       " 'feature_2_time_26',\n",
       " 'feature_2_time_27',\n",
       " 'feature_2_time_28',\n",
       " 'feature_2_time_29',\n",
       " 'feature_2_time_30',\n",
       " 'feature_2_time_31',\n",
       " 'feature_2_time_32',\n",
       " 'feature_2_time_33',\n",
       " 'feature_2_time_34',\n",
       " 'feature_2_time_35',\n",
       " 'feature_2_time_36',\n",
       " 'feature_2_time_37',\n",
       " 'feature_2_time_38',\n",
       " 'feature_2_time_39',\n",
       " 'feature_3_time_0',\n",
       " 'feature_3_time_1',\n",
       " 'feature_3_time_2',\n",
       " 'feature_3_time_3',\n",
       " 'feature_3_time_4',\n",
       " 'feature_3_time_5',\n",
       " 'feature_3_time_6',\n",
       " 'feature_3_time_7',\n",
       " 'feature_3_time_8',\n",
       " 'feature_3_time_9',\n",
       " 'feature_3_time_10',\n",
       " 'feature_3_time_11',\n",
       " 'feature_3_time_12',\n",
       " 'feature_3_time_13',\n",
       " 'feature_3_time_14',\n",
       " 'feature_3_time_15',\n",
       " 'feature_3_time_16',\n",
       " 'feature_3_time_17',\n",
       " 'feature_3_time_18',\n",
       " 'feature_3_time_19',\n",
       " 'feature_3_time_20',\n",
       " 'feature_3_time_21',\n",
       " 'feature_3_time_22',\n",
       " 'feature_3_time_23',\n",
       " 'feature_3_time_24',\n",
       " 'feature_3_time_25',\n",
       " 'feature_3_time_26',\n",
       " 'feature_3_time_27',\n",
       " 'feature_3_time_28',\n",
       " 'feature_3_time_29',\n",
       " 'feature_3_time_30',\n",
       " 'feature_3_time_31',\n",
       " 'feature_3_time_32',\n",
       " 'feature_3_time_33',\n",
       " 'feature_3_time_34',\n",
       " 'feature_3_time_35',\n",
       " 'feature_3_time_36',\n",
       " 'feature_3_time_37',\n",
       " 'feature_3_time_38',\n",
       " 'feature_3_time_39',\n",
       " 'feature_4_time_0',\n",
       " 'feature_4_time_1',\n",
       " 'feature_4_time_2',\n",
       " 'feature_4_time_3',\n",
       " 'feature_4_time_4',\n",
       " 'feature_4_time_5',\n",
       " 'feature_4_time_6',\n",
       " 'feature_4_time_7',\n",
       " 'feature_4_time_8',\n",
       " 'feature_4_time_9',\n",
       " 'feature_4_time_10',\n",
       " 'feature_4_time_11',\n",
       " 'feature_4_time_12',\n",
       " 'feature_4_time_13',\n",
       " 'feature_4_time_14',\n",
       " 'feature_4_time_15',\n",
       " 'feature_4_time_16',\n",
       " 'feature_4_time_17',\n",
       " 'feature_4_time_18',\n",
       " 'feature_4_time_19',\n",
       " 'feature_4_time_20',\n",
       " 'feature_4_time_21',\n",
       " 'feature_4_time_22',\n",
       " 'feature_4_time_23',\n",
       " 'feature_4_time_24',\n",
       " 'feature_4_time_25',\n",
       " 'feature_4_time_26',\n",
       " 'feature_4_time_27',\n",
       " 'feature_4_time_28',\n",
       " 'feature_4_time_29',\n",
       " 'feature_4_time_30',\n",
       " 'feature_4_time_31',\n",
       " 'feature_4_time_32',\n",
       " 'feature_4_time_33',\n",
       " 'feature_4_time_34',\n",
       " 'feature_4_time_35',\n",
       " 'feature_4_time_36',\n",
       " 'feature_4_time_37',\n",
       " 'feature_4_time_38',\n",
       " 'feature_4_time_39',\n",
       " 'feature_5_time_0',\n",
       " 'feature_5_time_1',\n",
       " 'feature_5_time_2',\n",
       " 'feature_5_time_3',\n",
       " 'feature_5_time_4',\n",
       " 'feature_5_time_5',\n",
       " 'feature_5_time_6',\n",
       " 'feature_5_time_7',\n",
       " 'feature_5_time_8',\n",
       " 'feature_5_time_9',\n",
       " 'feature_5_time_10',\n",
       " 'feature_5_time_11',\n",
       " 'feature_5_time_12',\n",
       " 'feature_5_time_13',\n",
       " 'feature_5_time_14',\n",
       " 'feature_5_time_15',\n",
       " 'feature_5_time_16',\n",
       " 'feature_5_time_17',\n",
       " 'feature_5_time_18',\n",
       " 'feature_5_time_19',\n",
       " 'feature_5_time_20',\n",
       " 'feature_5_time_21',\n",
       " 'feature_5_time_22',\n",
       " 'feature_5_time_23',\n",
       " 'feature_5_time_24',\n",
       " 'feature_5_time_25',\n",
       " 'feature_5_time_26',\n",
       " 'feature_5_time_27',\n",
       " 'feature_5_time_28',\n",
       " 'feature_5_time_29',\n",
       " 'feature_5_time_30',\n",
       " 'feature_5_time_31',\n",
       " 'feature_5_time_32',\n",
       " 'feature_5_time_33',\n",
       " 'feature_5_time_34',\n",
       " 'feature_5_time_35',\n",
       " 'feature_5_time_36',\n",
       " 'feature_5_time_37',\n",
       " 'feature_5_time_38',\n",
       " 'feature_5_time_39',\n",
       " 'feature_6_time_0',\n",
       " 'feature_6_time_1',\n",
       " 'feature_6_time_2',\n",
       " 'feature_6_time_3',\n",
       " 'feature_6_time_4',\n",
       " 'feature_6_time_5',\n",
       " 'feature_6_time_6',\n",
       " 'feature_6_time_7',\n",
       " 'feature_6_time_8',\n",
       " 'feature_6_time_9',\n",
       " 'feature_6_time_10',\n",
       " 'feature_6_time_11',\n",
       " 'feature_6_time_12',\n",
       " 'feature_6_time_13',\n",
       " 'feature_6_time_14',\n",
       " 'feature_6_time_15',\n",
       " 'feature_6_time_16',\n",
       " 'feature_6_time_17',\n",
       " 'feature_6_time_18',\n",
       " 'feature_6_time_19',\n",
       " 'feature_6_time_20',\n",
       " 'feature_6_time_21',\n",
       " 'feature_6_time_22',\n",
       " 'feature_6_time_23',\n",
       " 'feature_6_time_24',\n",
       " 'feature_6_time_25',\n",
       " 'feature_6_time_26',\n",
       " 'feature_6_time_27',\n",
       " 'feature_6_time_28',\n",
       " 'feature_6_time_29',\n",
       " 'feature_6_time_30',\n",
       " 'feature_6_time_31',\n",
       " 'feature_6_time_32',\n",
       " 'feature_6_time_33',\n",
       " 'feature_6_time_34',\n",
       " 'feature_6_time_35',\n",
       " 'feature_6_time_36',\n",
       " 'feature_6_time_37',\n",
       " 'feature_6_time_38',\n",
       " 'feature_6_time_39',\n",
       " 'feature_7_time_0',\n",
       " 'feature_7_time_1',\n",
       " 'feature_7_time_2',\n",
       " 'feature_7_time_3',\n",
       " 'feature_7_time_4',\n",
       " 'feature_7_time_5',\n",
       " 'feature_7_time_6',\n",
       " 'feature_7_time_7',\n",
       " 'feature_7_time_8',\n",
       " 'feature_7_time_9',\n",
       " 'feature_7_time_10',\n",
       " 'feature_7_time_11',\n",
       " 'feature_7_time_12',\n",
       " 'feature_7_time_13',\n",
       " 'feature_7_time_14',\n",
       " 'feature_7_time_15',\n",
       " 'feature_7_time_16',\n",
       " 'feature_7_time_17',\n",
       " 'feature_7_time_18',\n",
       " 'feature_7_time_19',\n",
       " 'feature_7_time_20',\n",
       " 'feature_7_time_21',\n",
       " 'feature_7_time_22',\n",
       " 'feature_7_time_23',\n",
       " 'feature_7_time_24',\n",
       " 'feature_7_time_25',\n",
       " 'feature_7_time_26',\n",
       " 'feature_7_time_27',\n",
       " 'feature_7_time_28',\n",
       " 'feature_7_time_29',\n",
       " 'feature_7_time_30',\n",
       " 'feature_7_time_31',\n",
       " 'feature_7_time_32',\n",
       " 'feature_7_time_33',\n",
       " 'feature_7_time_34',\n",
       " 'feature_7_time_35',\n",
       " 'feature_7_time_36',\n",
       " 'feature_7_time_37',\n",
       " 'feature_7_time_38',\n",
       " 'feature_7_time_39',\n",
       " 'feature_8_time_0',\n",
       " 'feature_8_time_1',\n",
       " 'feature_8_time_2',\n",
       " 'feature_8_time_3',\n",
       " 'feature_8_time_4',\n",
       " 'feature_8_time_5',\n",
       " 'feature_8_time_6',\n",
       " 'feature_8_time_7',\n",
       " 'feature_8_time_8',\n",
       " 'feature_8_time_9',\n",
       " 'feature_8_time_10',\n",
       " 'feature_8_time_11',\n",
       " 'feature_8_time_12',\n",
       " 'feature_8_time_13',\n",
       " 'feature_8_time_14',\n",
       " 'feature_8_time_15',\n",
       " 'feature_8_time_16',\n",
       " 'feature_8_time_17',\n",
       " 'feature_8_time_18',\n",
       " 'feature_8_time_19',\n",
       " 'feature_8_time_20',\n",
       " 'feature_8_time_21',\n",
       " 'feature_8_time_22',\n",
       " 'feature_8_time_23',\n",
       " 'feature_8_time_24',\n",
       " 'feature_8_time_25',\n",
       " 'feature_8_time_26',\n",
       " 'feature_8_time_27',\n",
       " 'feature_8_time_28',\n",
       " 'feature_8_time_29',\n",
       " 'feature_8_time_30',\n",
       " 'feature_8_time_31',\n",
       " 'feature_8_time_32',\n",
       " 'feature_8_time_33',\n",
       " 'feature_8_time_34',\n",
       " 'feature_8_time_35',\n",
       " 'feature_8_time_36',\n",
       " 'feature_8_time_37',\n",
       " 'feature_8_time_38',\n",
       " 'feature_8_time_39']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=df, continuous_features=[],categorical_features=df.columns.tolist()[:-1],outcome_name=\"resp_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2d = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80000, 9, 40])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_2d.view(-1, features, time_points).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetPlus(\n",
       "  (backbone): Sequential(\n",
       "    (0): ResBlockPlus(\n",
       "      (convblock1): ConvBlock(\n",
       "        (0): Conv1d(9, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock2): ConvBlock(\n",
       "        (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock3): ConvBlock(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): ConvBlock(\n",
       "        (0): Conv1d(9, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): Add\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (1): ResBlockPlus(\n",
       "      (convblock1): ConvBlock(\n",
       "        (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock2): ConvBlock(\n",
       "        (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock3): ConvBlock(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): ConvBlock(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (add): Add\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (2): ResBlockPlus(\n",
       "      (convblock1): ConvBlock(\n",
       "        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock2): ConvBlock(\n",
       "        (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (convblock3): ConvBlock(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (add): Add\n",
       "      (act): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): GAP1d(\n",
       "      (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "      (flatten): Reshape(bs)\n",
       "    )\n",
       "    (1): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom model that transforms 2D data to 3D format and applies the original model\n",
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomModel, self).__init()\n",
    "        self.original_model = original_model\n",
    "\n",
    "    def forward(self, input_2d):\n",
    "        # Reshape 2D data to 3D format\n",
    "        reshaped_data = input_2d.view(-1, features, time_points)\n",
    "        # Apply the original model's forward pass\n",
    "        output = self.original_model(reshaped_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '_CustomModel__init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Instantiate the custom model using your existing model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m learn_model \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcpu()  \u001b[39m# Assuming this is your trained model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m custom_model \u001b[39m=\u001b[39m CustomModel(learn_model)\n",
      "Cell \u001b[0;32mIn[62], line 4\u001b[0m, in \u001b[0;36mCustomModel.__init__\u001b[0;34m(self, original_model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, original_model):\n\u001b[0;32m----> 4\u001b[0m     \u001b[39msuper\u001b[39;49m(CustomModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m__init()\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_model \u001b[39m=\u001b[39m original_model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '_CustomModel__init'"
     ]
    }
   ],
   "source": [
    "# Instantiate the custom model using your existing model\n",
    "learn_model = learn.model.cpu()  # Assuming this is your trained model\n",
    "custom_model = CustomModel(learn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CustomTSaiModel' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformed_data \u001b[39m=\u001b[39m custom_model(input_2d)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CustomTSaiModel' object is not callable"
     ]
    }
   ],
   "source": [
    "transformed_data = custom_model(input_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '_CustomModel__init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Instantiate the custom model using your existing model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m learn_model \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcpu()  \u001b[39m# Assuming this is your trained model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m custom_model \u001b[39m=\u001b[39m CustomModel(learn_model)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Provide the 2D data to the custom model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m#input_2d = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#transformed_data = custom_model(input_2d)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m# Using sklearn backend\u001b[39;00m\n\u001b[1;32m     26\u001b[0m m \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39mModel(model\u001b[39m=\u001b[39mcustom_model, backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPYT\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 4\u001b[0m, in \u001b[0;36mCustomModel.__init__\u001b[0;34m(self, original_model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, original_model):\n\u001b[0;32m----> 4\u001b[0m     \u001b[39msuper\u001b[39;49m(CustomModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m__init()\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_model \u001b[39m=\u001b[39m original_model\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '_CustomModel__init'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Provide the 2D data to the custom model\n",
    "input_2d = torch.tensor(df.iloc[:, :-1].values, dtype=torch.float32)\n",
    "transformed_data = custom_model(input_2d)\n",
    "\n",
    "# Continue with DICE-ML for explanations and fairness assessments\n",
    "\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=custom_model, backend=\"PYT\")\n",
    "\n",
    "# Using method=gradient for generating counterfactuals\n",
    "exp = dice_ml.Dice(d, m, method=\"gradient\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 9, 7], expected input[1, 1, 360] to have 9 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m m \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39mModel(model\u001b[39m=\u001b[39mlearn\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcpu(), backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPYT\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# Using method=random for generating CFs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m exp \u001b[39m=\u001b[39m dice_ml\u001b[39m.\u001b[39;49mDice(d, m, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgradient\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/dice.py:22\u001b[0m, in \u001b[0;36mDice.__init__\u001b[0;34m(self, data_interface, model_interface, method, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data_interface, model_interface, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Init method\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[39m    :param data_interface: an interface to access data related params.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    :param model_interface: an interface to access the output or gradients of a trained ML model.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m    :param method: Name of the method to use for generating counterfactuals\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecide_implementation_type(data_interface, model_interface, method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/dice.py:32\u001b[0m, in \u001b[0;36mDice.decide_implementation_type\u001b[0;34m(self, data_interface, model_interface, method, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[39mraise\u001b[39;00m UserConfigValidationException(\n\u001b[1;32m     29\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mPrivate data interface is not supported with kdtree explainer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m since kdtree explainer needs access to entire training data\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m decide(model_interface, method)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data_interface, model_interface, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/explainer_interfaces/dice_pytorch.py:36\u001b[0m, in \u001b[0;36mDicePyTorch.__init__\u001b[0;34m(self, data_interface, model_interface)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface\u001b[39m.\u001b[39mcreate_ohe_params(temp_ohe_data)\n\u001b[1;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_categorical_feature_indexes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoded_continuous_feature_indexes, \\\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_minx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_maxx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcont_precisions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_interface\u001b[39m.\u001b[39mget_data_params_for_gradient_dice()\n\u001b[0;32m---> 36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_output_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_num_output_nodes(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_interface\u001b[39m.\u001b[39;49mohe_encoded_feature_names))\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     38\u001b[0m \u001b[39m# variables required to generate CFs - see generate_counterfactuals() for more info\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/model_interfaces/pytorch_model.py:57\u001b[0m, in \u001b[0;36mPyTorchModel.get_num_output_nodes\u001b[0;34m(self, inp_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_num_output_nodes\u001b[39m(\u001b[39mself\u001b[39m, inp_size):\n\u001b[1;32m     56\u001b[0m     temp_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, inp_size)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_output(temp_input)\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/dice_ml/model_interfaces/pytorch_model.py:41\u001b[0m, in \u001b[0;36mPyTorchModel.get_output\u001b[0;34m(self, input_instance, model_score, transform_data, out_tensor)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(input_instance):\n\u001b[1;32m     40\u001b[0m     input_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mtransform(input_instance)\u001b[39m.\u001b[39mto_numpy())\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 41\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_tensor)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m out_tensor:\n\u001b[1;32m     43\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/tsai/models/ResNetPlus.py:41\u001b[0m, in \u001b[0;36mResBlockPlus.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     40\u001b[0m     res \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 41\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvblock1(x)\n\u001b[1;32m     42\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock2(x)\n\u001b[1;32m     43\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvblock3(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 9, 7], expected input[1, 1, 360] to have 9 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=learn.model.cpu(), backend=\"PYT\")\n",
    "# Using method=random for generating CFs\n",
    "exp = dice_ml.Dice(d, m, method=\"gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(x_test[1:3], total_CFs=4, desired_class=\"opposite\")\n",
    "# highlight only the changes\n",
    "dice_exp.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "# Now you can use 'exp' to explain model predictions and assess fairness\n",
    "# For example, you can generate counterfactuals as follows:\n",
    "query_instance = df.iloc[0, :-1].to_dict()  # Assuming you want to explain the first instance\n",
    "explanation = exp.generate_counterfactuals(query_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import dice_ml\n",
    "from dice_ml import Dice\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Preliminaries: Loading the data and ML model\n",
    "\n",
    "dataset = helpers.load_adult_income_dataset().sample(5000)  # downsampling to reduce ML model fitting time\n",
    "helpers.get_adult_data_info()\n",
    "\n",
    "target = dataset[\"income\"]\n",
    "\n",
    "# Split data into train and test\n",
    "datasetX = dataset.drop(\"income\", axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(datasetX,\n",
    "                                                    target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=target)\n",
    "\n",
    "numerical = [\"age\", \"hours_per_week\"]\n",
    "categorical = x_train.columns.difference(numerical)\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')\n",
    "m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "\n",
    "#Local feature importance\n",
    "\n",
    "#We first generate counterfactuals for a given input point.\n",
    "\n",
    "exp = Dice(d, m, method=\"random\")\n",
    "query_instance = x_train[1:2]\n",
    "e1 = exp.generate_counterfactuals(query_instance, total_CFs=10, desired_range=None,\n",
    "                                  desired_class=\"opposite\",\n",
    "                                  permitted_range=None, features_to_vary=\"all\")\n",
    "e1.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#These can now be used to calculate the feature importance scores.\n",
    "\n",
    "imp = exp.local_feature_importance(query_instance, cf_examples_list=e1.cf_examples_list)\n",
    "print(imp.local_importance)\n",
    "\n",
    "#Feature importance can also be estimated directly, by leaving the cf_examples_list argument blank.\n",
    "\n",
    "imp = exp.local_feature_importance(query_instance, posthoc_sparsity_param=None)\n",
    "print(imp.local_importance)\n",
    "\n",
    "##Global importance\n",
    "\n",
    "#For global importance, we need to generate counterfactuals for a representative sample of the dataset.\n",
    "\n",
    "cobj = exp.global_feature_importance(x_train[0:10], total_CFs=10, posthoc_sparsity_param=None)\n",
    "print(cobj.summary_importance)\n",
    "\n",
    "#Convert the counterfactual output to json\n",
    "\n",
    "json_str = cobj.to_json()\n",
    "print(json_str)\n",
    "\n",
    "#Convert the json output to a counterfactual object\n",
    "\n",
    "imp_r = imp.from_json(json_str)\n",
    "print([o.visualize_as_dataframe(show_only_changes=True) for o in imp_r.cf_examples_list])\n",
    "print(imp_r.local_importance)\n",
    "print(imp_r.summary_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Generating counterfactual explanations with any ML model  ## model-agnostic\n",
    "\n",
    "#The goal of this notebook is to show how to generate CFs for ML models using frameworks other than TensorFlow or PyTorch. We show how to generate diverse CFs by three methods:\n",
    "\n",
    "#    Independent random sampling of features (method_name='random')\n",
    "#    Genetic algorithm (method_name='genetic')\n",
    "#    Querying a KD tree (method_name='kdtree')\n",
    "\n",
    "#We use scikit-learn models for demonstration.\n",
    "#1. Independent random sampling of features\n",
    "\n",
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Loading dataset\n",
    "\n",
    "#We use the \"adult\" income dataset from UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/adult). We transform the data as described in dice_ml.utils.helpers module.\n",
    "\n",
    "dataset = helpers.load_adult_income_dataset()\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')\n",
    "\n",
    "#Training a custom ML model\n",
    "\n",
    "#Below, we build an ML model using scikit-learn to demonstrate how our methods can work with any sklearn model.\n",
    "\n",
    "target = dataset[\"income\"]\n",
    "# Split data into train and test\n",
    "datasetX = dataset.drop(\"income\", axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(datasetX,\n",
    "                                                    target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=target)\n",
    "\n",
    "numerical = [\"age\", \"hours_per_week\"]\n",
    "categorical = x_train.columns.difference(numerical)\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "# provide the trained ML model to DiCE's model object\n",
    "backend = 'sklearn'\n",
    "m = dice_ml.Model(model=model, backend=backend)\n",
    "\n",
    "#Generate diverse counterfactuals\n",
    "\n",
    "# initiate DiCE\n",
    "exp_random = dice_ml.Dice(d, m, method=\"random\")\n",
    "\n",
    "query_instances = x_train[4:6]\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_random = exp_random.generate_counterfactuals(query_instances, total_CFs=2, desired_class=\"opposite\", verbose=False)\n",
    "\n",
    "dice_exp_random.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#It can be observed that the random sampling method produces less sparse CFs in contrast to current DiCE's implementation. The sparsity issue with random sampling worsens with increasing total_CFs\n",
    "\n",
    "#Further, different sets of counterfactuals can be generated with different random seeds.\n",
    "\n",
    "# generate counterfactuals\n",
    "# default random seed is 17\n",
    "dice_exp_random = exp_random.generate_counterfactuals(query_instances,\n",
    "                                                      total_CFs=4,\n",
    "                                                      desired_class=\"opposite\",\n",
    "                                                      random_seed=9)\n",
    "\n",
    "dice_exp_random.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#Selecting the features to vary\n",
    "\n",
    "#Here, you can ensure that DiCE varies only features that it makes sense to vary.\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_random = exp_random.generate_counterfactuals(\n",
    "        query_instances, total_CFs=4, desired_class=\"opposite\",\n",
    "        features_to_vary=['workclass', 'education', 'occupation', 'hours_per_week'])\n",
    "\n",
    "dice_exp_random.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#Choosing feature ranges\n",
    "\n",
    "#Since the features are sampled randomly, they can freely vary across their range. In the below example, we show how range of continuous features can be controlled using permitted_range parameter that can now be passed during CF generation.\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_random = exp_random.generate_counterfactuals(\n",
    "    query_instances, total_CFs=4, desired_class=\"opposite\",\n",
    "    permitted_range={'age': [22, 50], 'hours_per_week': [40, 60]})\n",
    "\n",
    "dice_exp_random.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#2. Genetic Algorithm\n",
    "\n",
    "#Here, we show how to use DiCE can be used to generate CFs for any ML model by using the genetic algorithm to find the best counterfactuals close to the query point. The genetic algorithm converges quickly, and promotes diverse counterfactuals.\n",
    "#Training a custom ML model\n",
    "\n",
    "#Currently, the genetic algorithm method works with scikit-learn models. We will use the same model as shown previously in the notebook. Support for Tensorflow 1&2 and Pytorch will be implemented soon.\n",
    "#Generate diverse counterfactuals\n",
    "\n",
    "# initiate DiceGenetic\n",
    "exp_genetic = dice_ml.Dice(d, m, method='genetic')\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_genetic = exp_genetic.generate_counterfactuals(query_instances, total_CFs=4, desired_class=\"opposite\", verbose=True)\n",
    "\n",
    "dice_exp_genetic.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#e can also ensure that the genetic algorithm also only varies the features that you wish to vary\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_genetic = exp_genetic.generate_counterfactuals(\n",
    "    query_instances, total_CFs=2, desired_class=\"opposite\",\n",
    "    features_to_vary=['workclass', 'education', 'occupation', 'hours_per_week'])\n",
    "dice_exp_genetic.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#You can also constrain the features to vary only within the permitted range\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_genetic = exp_genetic.generate_counterfactuals(\n",
    "    query_instances, total_CFs=2, desired_class=\"opposite\",\n",
    "    permitted_range={'age': [22, 50], 'hours_per_week': [40, 60]})\n",
    "dice_exp_genetic.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#3. Querying a KD Tree\n",
    "\n",
    "#Here, we show how to use DiCE can be used to generate CFs for any ML model by finding the closest points in the dataset that give the output as the desired class. We do this efficiently by building KD trees for each class, and querying the KD tree of the desired class to find the k closest counterfactuals from the dataset. The idea behind finding the closest points from the training data itself is to ensure that the counterfactuals displayed are feasible.\n",
    "#Training a custom ML model\n",
    "\n",
    "#Currently, the KD tree algorithm method works with scikit-learn models. Again, we will use the same model as shown previously in the notebook. Support for Tensorflow 1&2 and Pytorch will be implemented soon.\n",
    "#Generate diverse counterfactuals\n",
    "\n",
    "# initiate DiceKD\n",
    "exp_KD = dice_ml.Dice(d, m, method='kdtree')\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_KD = exp_KD.generate_counterfactuals(query_instances, total_CFs=4, desired_class=\"opposite\")\n",
    "\n",
    "dice_exp_KD.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#Selecting the features to vary\n",
    "\n",
    "#Here, again, you can vary only features that you wish to vary. Please note that the output counterfactuals are only from the training data. If you want other counterfactuals, please use the random or genetic method.\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_KD = exp_KD.generate_counterfactuals(\n",
    "    query_instances, total_CFs=4, desired_class=\"opposite\",\n",
    "    features_to_vary=['age', 'workclass', 'education', 'occupation', 'hours_per_week'])\n",
    "\n",
    "dice_exp_KD.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#Selecting the feature ranges\n",
    "\n",
    "#Here, you can control the ranges of continuous features.\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp_KD = exp_KD.generate_counterfactuals(\n",
    "    query_instances, total_CFs=5, desired_class=\"opposite\",\n",
    "    permitted_range={'age': [30, 50], 'hours_per_week': [40, 60]})\n",
    "dice_exp_KD.visualize_as_dataframe(show_only_changes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# DiCE imports\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = helpers.load_adult_income_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>18</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass     education marital_status    occupation   race  \\\n",
       "0       28        Private     Bachelors         Single  White-Collar  White   \n",
       "1       30  Self-Employed         Assoc        Married  Professional  White   \n",
       "2       32        Private  Some-college        Married  White-Collar  White   \n",
       "3       20        Private  Some-college         Single       Service  White   \n",
       "4       41  Self-Employed  Some-college        Married  White-Collar  White   \n",
       "...    ...            ...           ...            ...           ...    ...   \n",
       "26043   28        Private       HS-grad        Married  White-Collar  White   \n",
       "26044   18        Private        School         Single   Blue-Collar  White   \n",
       "26045   22        Private  Some-college         Single  White-Collar  White   \n",
       "26046   42  Self-Employed     Bachelors       Divorced  White-Collar  Other   \n",
       "26047   23        Private  Some-college       Divorced  White-Collar  White   \n",
       "\n",
       "       gender  hours_per_week  income  \n",
       "0      Female              60       0  \n",
       "1        Male              65       1  \n",
       "2        Male              50       0  \n",
       "3      Female              35       0  \n",
       "4        Male              50       0  \n",
       "...       ...             ...     ...  \n",
       "26043    Male              40       0  \n",
       "26044    Male              55       0  \n",
       "26045  Female              40       0  \n",
       "26046    Male              30       0  \n",
       "26047    Male              40       0  \n",
       "\n",
       "[26048 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_array, columns = ['Column_A','Column_B','Column_C'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to put X_trainvalid and Y_trainvalid into a data set format\n",
    "\n",
    "\n",
    "d = dice_ml.Data(dataframe=train_dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target = dataset[\"income\"]\n",
    "train_dataset, test_dataset, y_train, y_test = train_test_split(dataset,\n",
    "                                                                target,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=0,\n",
    "                                                                stratify=target)\n",
    "x_train = train_dataset.drop('income', axis=1)\n",
    "x_test = test_dataset.drop('income', axis=1)\n",
    "\n",
    "# Step 1: dice_ml.Data\n",
    "d = dice_ml.Data(dataframe=train_dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')\n",
    "\n",
    "\n",
    "#The loss is defined by three component: validity (does the CF have the desired model output), \n",
    "#proximity (distance of CF from original point should be low), and diversity (multiple CFs should change different features). \n",
    "#The DiCE loss formulation is described in the paper, Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations.\n",
    "\n",
    "\n",
    "backend = 'PYT'  # needs pytorch installed\n",
    "ML_modelpath = helpers.get_adult_income_modelpath(backend=backend)\n",
    "m = dice_ml.Model(model_path=ML_modelpath, backend=backend,  func=\"ohe-min-max\")\n",
    "\n",
    "exp = dice_ml.Dice(d, m, method=\"gradient\")\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(x_test[1:3], total_CFs=4, desired_class=\"opposite\")\n",
    "# highlight only the changes\n",
    "dice_exp.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "#We can also use method-agnostic explainers like \"random\" or \"genetic\".\n",
    "\n",
    "m = dice_ml.Model(model_path=ML_modelpath, backend=backend, func=\"ohe-min-max\")\n",
    "exp = dice_ml.Dice(d, m, method=\"random\")\n",
    "\n",
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(x_test[1:3], total_CFs=4, desired_class=\"opposite\")\n",
    "# highlight only the changes\n",
    "dice_exp.visualize_as_dataframe(show_only_changes=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
