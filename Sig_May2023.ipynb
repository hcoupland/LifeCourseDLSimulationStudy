{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import timeit\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import sklearn.metrics as skm\n",
    "import importlib\n",
    "import fastai\n",
    "import tsai\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import shap\n",
    "importlib.reload(fastai)\n",
    "importlib.reload(tsai)\n",
    "import signatory\n",
    "import timeit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import Data_load_neat as Data_load\n",
    "import LM_cv_neat\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from tsai.all import *\n",
    "from tsai.data.validation import combine_split_data, get_splits\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.tslearner import TSClassifier\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import FastAIPruningCallback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, ReduceLROnPlateau\n",
    "from fastai.data.transforms import Categorize\n",
    "from fastai.losses import BCEWithLogitsLossFlat, FocalLoss, FocalLossFlat\n",
    "from fastai.metrics import accuracy, BrierScore, F1Score, RocAucBinary\n",
    "\n",
    "\n",
    "import Data_load_neat as Data_load\n",
    "import MLmodel_opt_learner_neat as MLmodel_opt_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in arguments from command line\n",
    "name = \"data_2real5newbigdet\"\n",
    "model_name=\"ResNet\"\n",
    "randnum_split=3\n",
    "epochs=8\n",
    "device = 1\n",
    "filepath=\"/home/DIDE/smishra/Simulations/\"\n",
    "folds=5\n",
    "randnum=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 9, 40) (100000, 40) (100000, 1)\n",
      "(100000,)\n",
      "Random state set:3, cuda used: True\n",
      "Counter({0.0: 93055, 1.0: 6945}) Counter({0.0: 74444, 1.0: 5556}) Counter({0.0: 18611, 1.0: 1389})\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_raw = Data_load.load_data(name=name,filepath=filepath)\n",
    "\n",
    "## Function to obtain the train/test split\n",
    "X_trainvalid, Y_trainvalid, X_test, Y_test, splits = Data_load.split_data(X=X_raw,Y=y_raw,randnum=randnum_split)\n",
    "\n",
    "## Now scale all the data for ease (can fix this later)\n",
    "X_scaled=Data_load.prep_data(X_raw,splits)\n",
    "\n",
    "X_trainvalid_s, X_test_s=X_scaled[splits[0]], X_scaled[splits[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_bin(pred, y_test):\n",
    "    # function to output accuracy, precision, recall, f1-score, AUC score and area under precision-recall curve and classification matrix\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    prec = precision_score(y_test,pred)\n",
    "    rec = recall_score( y_test,pred)\n",
    "    fone = f1_score(y_test,pred)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    prc= average_precision_score(y_test,pred)\n",
    "    print(\"{:<40} {:.6f}\".format(\"Accuracy:\", acc))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Precision:\", prec))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Recall:\", rec))\n",
    "    print(\"{:<40} {:.6f}\".format(\"F1 score:\", fone))\n",
    "    print(\"{:<40} {:.6f}\".format(\"AUC score:\", auc))\n",
    "\n",
    "    LR00 = np.sum(pred[(pred == y_test) & (y_test == 0)] + 1)\n",
    "    LR10 = np.sum(pred[(pred != y_test) & (y_test == 1)] + 1)\n",
    "    LR01 = np.sum(pred[(pred != y_test) & (y_test == 0)])\n",
    "    LR11 = np.sum(pred[(pred == y_test) & (y_test == 1)])\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 0 when actually 0:\", LR00))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 0 when actually 1:\", LR10))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 1 when actually 0:\", LR01))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 1 when actually 1:\", LR11))\n",
    "    return acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LM_cv_neat\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                1.000000\n",
      "Precision:                               1.000000\n",
      "Recall:                                  1.000000\n",
      "F1 score:                                1.000000\n",
      "AUC score:                               1.000000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             0.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             1389.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.10222931e+01, -1.12651005e+01, -1.09118872e+01,\n",
       "        -1.08828640e+01, -1.08392677e+01, -1.08580055e+01,\n",
       "        -1.07901697e+01, -1.08152561e+01, -1.08252182e+01,\n",
       "        -1.08437624e+01, -1.08936977e+01, -1.08736610e+01,\n",
       "        -1.08684416e+01, -1.08235626e+01, -1.08113194e+01,\n",
       "        -1.08230591e+01, -1.08848696e+01, -1.08040190e+01,\n",
       "        -1.08010397e+01, -1.08326216e+01, -4.25344624e-05,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.78321169e-06,\n",
       "        -4.51730120e-05,  5.31642718e-06, -4.24342979e-05,\n",
       "         5.90219952e-06,  4.92972367e-06,  4.87788157e-07,\n",
       "         0.00000000e+00, -2.19462936e-06,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.02286435e-06, -4.60505653e-05,\n",
       "         0.00000000e+00, -3.30966941e-07,  0.00000000e+00,\n",
       "         0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lr just for final row\n",
    "X_LRtrain=np.squeeze(X_trainvalid[:,-1,:])\n",
    "X_LRtest=np.squeeze(X_test[:,-1,:])\n",
    "\n",
    "\n",
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11 =LM_cv_neat.metrics_bin(LRpred, Y_test)\n",
    "\n",
    "LRmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sig_func(X_trainvalid, X_test, K):\n",
    "\n",
    "    num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "    num_samples_test = np.shape(X_test)[0]\n",
    "    sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "    X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "    X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "    \n",
    "\n",
    "    for i in range(0, num_samples):\n",
    "        xt = np.arange(0, num_timepoints)  ## time/age\n",
    "        xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = copy.copy(xtT)\n",
    "        for j in range(0, num_features):\n",
    "        \n",
    "            x1 = X_trainvalid[i, j, :]\n",
    "            x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "            path = torch.cat((path,x1T), 1)\n",
    "\n",
    "            #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "        path2 = path.unsqueeze(0)\n",
    "        X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "    for i in range(0, num_samples_test):\n",
    "        xt = np.arange(0, num_timepoints)  ## time/age\n",
    "        xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = copy.copy(xtT)\n",
    "        for j in range(0, num_features):\n",
    "        \n",
    "            x1 = X_test[i, j, :]\n",
    "            x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "            path = torch.cat((path,x1T), 1)\n",
    "\n",
    "            #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "        path2 = path.unsqueeze(0)\n",
    "        X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "    # function to reshape the data to flatten the time/feature dimensions into one\n",
    "    X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "    X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))\n",
    "\n",
    "    return X_LRtrainvalid, X_LRtest\n",
    "\n",
    "\n",
    "\n",
    "def SIGmodel_block(X_trainvalid, Y_trainvalid, X_test, Y_test, sig_depth, K, randnum=8):\n",
    "    # function to fit and analyse the logistic regression model\n",
    "    \n",
    "    # random seed\n",
    "    Data_load.random_seed(randnum)\n",
    "\n",
    "    # scale and one-hot the data\n",
    "    #X_scaled=Data_load.prep_data(X, splits)\n",
    "    #XStrainvalid=X_scaled[splits[0]]\n",
    "    #XStest=X_scaled[splits[1]]\n",
    "\n",
    "    # flatten the data\n",
    "    X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, sig_depth, K)\n",
    "\n",
    "    # fit the logistic regression model to the train data\n",
    "    start = timeit.default_timer()\n",
    "    LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "    stop = timeit.default_timer()\n",
    "    runtime=stop - start\n",
    "\n",
    "    # get model predictions on the test data\n",
    "    LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "    # get output metrics for test data\n",
    "    acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)\n",
    "    return runtime, acc, prec, rec, fone, auc, prc,  LR00, LR01, LR10, LR11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K=3\n",
    "\n",
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "num_samples_test = np.shape(X_test)[0]\n",
    "sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "\n",
    "X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = copy.copy(xtT)\n",
    "    for j in range(0, num_features):\n",
    "    \n",
    "        x1 = X_trainvalid[i, j, :]\n",
    "        x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = torch.cat((path,x1T), 1)\n",
    "\n",
    "        #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "for i in range(0, num_samples_test):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = copy.copy(xtT)\n",
    "    for j in range(0, num_features):\n",
    "    \n",
    "        x1 = X_test[i, j, :]\n",
    "        x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = torch.cat((path,x1T), 1)\n",
    "\n",
    "        #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "# function to reshape the data to flatten the time/feature dimensions into one\n",
    "X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X_LRtrain, X_LRtest \u001b[39m=\u001b[39m Sig_func(X_trainvalid, X_test, K\u001b[39m=\u001b[39mK)\n\u001b[1;32m      5\u001b[0m \u001b[39m# fit the logistic regression model to the train data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m LRmodel \u001b[39m=\u001b[39m LogisticRegression(penalty\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ml1\u001b[39;49m\u001b[39m\"\u001b[39;49m, tol\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, solver\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m,random_state\u001b[39m=\u001b[39;49mrandnum)\u001b[39m.\u001b[39;49mfit(X_LRtrain, Y_trainvalid)\n\u001b[1;32m      8\u001b[0m \u001b[39m# get model predictions on the test data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m LRpred \u001b[39m=\u001b[39m LRmodel\u001b[39m.\u001b[39mpredict(X_LRtest)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1589\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1588\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1589\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m   1590\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m   1591\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1592\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer),\n\u001b[1;32m   1593\u001b[0m )(\n\u001b[1;32m   1594\u001b[0m     path_func(\n\u001b[1;32m   1595\u001b[0m         X,\n\u001b[1;32m   1596\u001b[0m         y,\n\u001b[1;32m   1597\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[1;32m   1598\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1599\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m   1600\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1601\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1602\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1603\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1604\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[1;32m   1605\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1606\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1607\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1608\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1609\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1610\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[1;32m   1611\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1612\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1614\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[1;32m   1615\u001b[0m )\n\u001b[1;32m   1617\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:864\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    861\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[1;32m    862\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[0;32m--> 864\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[1;32m    865\u001b[0m         X,\n\u001b[1;32m    866\u001b[0m         target,\n\u001b[1;32m    867\u001b[0m         sample_weight,\n\u001b[1;32m    868\u001b[0m         loss,\n\u001b[1;32m    869\u001b[0m         alpha,\n\u001b[1;32m    870\u001b[0m         beta,\n\u001b[1;32m    871\u001b[0m         max_iter,\n\u001b[1;32m    872\u001b[0m         tol,\n\u001b[1;32m    873\u001b[0m         verbose,\n\u001b[1;32m    874\u001b[0m         random_state,\n\u001b[1;32m    875\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    876\u001b[0m         max_squared_sum,\n\u001b[1;32m    877\u001b[0m         warm_start_sag,\n\u001b[1;32m    878\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    879\u001b[0m     )\n\u001b[1;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    883\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[1;32m    885\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/hfixed/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:327\u001b[0m, in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    326\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[0;32m--> 327\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[1;32m    328\u001b[0m     dataset,\n\u001b[1;32m    329\u001b[0m     coef_init,\n\u001b[1;32m    330\u001b[0m     intercept_init,\n\u001b[1;32m    331\u001b[0m     n_samples,\n\u001b[1;32m    332\u001b[0m     n_features,\n\u001b[1;32m    333\u001b[0m     n_classes,\n\u001b[1;32m    334\u001b[0m     tol,\n\u001b[1;32m    335\u001b[0m     max_iter,\n\u001b[1;32m    336\u001b[0m     loss,\n\u001b[1;32m    337\u001b[0m     step_size,\n\u001b[1;32m    338\u001b[0m     alpha_scaled,\n\u001b[1;32m    339\u001b[0m     beta_scaled,\n\u001b[1;32m    340\u001b[0m     sum_gradient_init,\n\u001b[1;32m    341\u001b[0m     gradient_memory_init,\n\u001b[1;32m    342\u001b[0m     seen_init,\n\u001b[1;32m    343\u001b[0m     num_seen_init,\n\u001b[1;32m    344\u001b[0m     fit_intercept,\n\u001b[1;32m    345\u001b[0m     intercept_sum_gradient,\n\u001b[1;32m    346\u001b[0m     intercept_decay,\n\u001b[1;32m    347\u001b[0m     is_saga,\n\u001b[1;32m    348\u001b[0m     verbose,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[1;32m    352\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    355\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K=4\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=K)\n",
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53731664 7.19942405]\n"
     ]
    }
   ],
   "source": [
    "class_weights=sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=[0,1], y=Y_trainvalid)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.930550\n",
      "Precision:                               0.000000\n",
      "Recall:                                  0.000000\n",
      "F1 score:                                0.000000\n",
      "AUC score:                               0.500000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             1389.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid[:,range(7,9),:], X_test[:,range(7,9),:], K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.930550\n",
      "Precision:                               0.000000\n",
      "Recall:                                  0.000000\n",
      "F1 score:                                0.000000\n",
      "AUC score:                               0.500000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             1389.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain, X_LRtest = LM_cv_neat.LM_func(X_trainvalid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 64981)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "Xpoly=poly.fit_transform(X_LRtrain)\n",
    "\n",
    "Xpoly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(Xpoly, Y_trainvalid)\n",
    "\n",
    "X_test_poly=poly.transform(X_LRtest)\n",
    "print(X_test_poly.shape)\n",
    "\n",
    "   # get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_test_poly)\n",
    "\n",
    "   # get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11 =metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFE(LogisticRegression(), 25)\n",
    "final_clf = SVC()\n",
    "rfe_model = Pipeline([(\"rfe\",selector),('model',final_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_model.fit(Xpoly,Y_trainvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "Y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.929250\n",
      "Precision:                               0.379630\n",
      "Recall:                                  0.029518\n",
      "F1 score:                                0.054776\n",
      "AUC score:                               0.512959\n",
      "Predicted 0 when actually 0:             18544.000000\n",
      "Predicted 0 when actually 1:             1348.000000\n",
      "Predicted 1 when actually 0:             67.000000\n",
      "Predicted 1 when actually 1:             41.000000\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid[:,range(7,9),:], X_test[:,range(7,9),:], K=K)\n",
    "\n",
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3 \n",
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "num_features=1\n",
    "num_samples_test = np.shape(X_test)[0]\n",
    "sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "\n",
    "    x1 = X_trainvalid[i, 8, :]\n",
    "    x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = torch.cat((xtT,x1T), 1)\n",
    "\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "for i in range(0, num_samples_test):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    \n",
    "    x1 = X_test[i, 8, :]\n",
    "    x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = torch.cat((xtT,x1T), 1)\n",
    "\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "# function to reshape the data to flatten the time/feature dimensions into one\n",
    "X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.929400\n",
      "Precision:                               0.394495\n",
      "Recall:                                  0.030958\n",
      "F1 score:                                0.057410\n",
      "AUC score:                               0.513706\n",
      "Predicted 0 when actually 0:             18545.000000\n",
      "Predicted 0 when actually 1:             1346.000000\n",
      "Predicted 1 when actually 0:             66.000000\n",
      "Predicted 1 when actually 1:             43.000000\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrainvalid, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,\n",
       "         67,  68,  69,  70,  72,  73,  75,  76,  77,  78,  79,  80,  81,\n",
       "         82,  83,  86,  87,  88,  91,  92,  93,  95,  96,  99, 100, 102,\n",
       "        115, 117, 461]),\n",
       " array([26948,  4272,  1688,   848,   510,   347,   245,   189,   155,\n",
       "          139,   104,    91,    70,    70,    60,    43,    41,    28,\n",
       "           28,    24,    27,    23,    17,    11,    14,    11,    10,\n",
       "            8,    13,    13,     6,     8,    13,    10,    10,     3,\n",
       "            4,     5,     7,    10,     5,     7,     4,    13,     8,\n",
       "           11,     3,     6,     5,     7,     8,    11,     5,     5,\n",
       "            4,     4,     3,     7,     4,     4,     3,     3,     2,\n",
       "            6,     3,     1,     2,     4,     2,     1,     1,     1,\n",
       "            1,     1,     3,     2,     2,     1,     2,     2,     1,\n",
       "            2,     1,     2,     1,     1,     1,     1,     2,     1,\n",
       "            1,     1,     1,     1]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rowsmin, unique_rowsmin_cnt = np.unique(X_LRtrainvalid, axis=0,return_counts=True)\n",
    "np.unique(unique_rowsmin_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  45,  49,  50,  51,  52,\n",
       "         54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,\n",
       "         69,  70,  72,  75,  83,  96, 461]),\n",
       " array([59600,  3370,   935,   287,   109,   119,   112,   106,    72,\n",
       "           82,    64,    48,    30,    21,    10,     6,     6,     1,\n",
       "            3,     1,     2,     1,     1,     2,     1,     4,     1,\n",
       "            2,     2,     3,     3,     3,     1,     1,     1,     4,\n",
       "            1,     1,     2,     1,     1,     1,     1,     1,     1,\n",
       "            1]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rowsmain, unique_rowsmain_cnt = np.unique(X_trainvalid[:,8,:], axis=0,return_counts=True)\n",
    "np.unique(unique_rowsmain_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.69792269e-07,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -7.28510167e-07,  2.65038999e-06,  5.56744219e-06]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LRtrain[0:10,0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other bits of proving why the signature is bad for this type of data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I think I'll start with showing it can be the same for different time series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 110)\n"
     ]
    }
   ],
   "source": [
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain1, X_LRtest1 = Sig_func(X_trainvalid, X_test, K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 10)\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "print(X_trainvalid.shape)\n",
    "print(X_LRtrain1.shape)\n",
    "print(9*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows1, unique_rows1_cnt = np.unique(X_LRtrain1, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows2, unique_rows2_cnt = np.unique(X_LRtrain, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain3, X_LRtest3 = Sig_func(X_trainvalid, X_test, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1110)\n"
     ]
    }
   ],
   "source": [
    "print(X_LRtrain3.shape) ## much bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows3, unique_rows3_cnt = np.unique(X_LRtrain3, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79998, 1110)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows3.shape ## almost all unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3]), array([79997,     1]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows3_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54788, 110)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  45,  46,  47,  49,  50,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  65,  66,  68,  70,  72,  74,\n",
       "         76,  78,  85, 106]),\n",
       " array([46726,  4355,  1442,   665,   419,   274,   172,   133,   105,\n",
       "           70,    67,    39,    26,    31,    22,    24,    18,    14,\n",
       "            7,    12,    10,     6,     8,    10,     6,     6,     2,\n",
       "            5,     5,     7,     6,     7,     6,     4,     4,     4,\n",
       "            2,     3,     5,     4,     3,     5,     6,     4,     4,\n",
       "            1,     3,     2,     1,     3,     2,     1,     1,     1,\n",
       "            1,     3,     1,     1,     2,     1,     2,     1,     2,\n",
       "            1,     1,     1,     1,     1,     1]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows2_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_org, unique_rows_org_cnt = np.unique(X_trainvalid, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "unique_rows_org, unique_rows_org_cnt = np.unique(X_trainvalid.reshape(num_samples,num_features*num_timepoints), axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 360)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_org.shape ## all unique 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    1,     2,     3,     4,     6,     8,     9,    10,    11,\n",
       "           12,    13,    14,    15,    17,    20,    21,    31,    32,\n",
       "           35,    36,    37,    49,    72,    75,    82,    87,    88,\n",
       "           97,    99,   102,   108,   113,   142,   211,   217,   220,\n",
       "          240,   243,   253,   265,   269,   270,   309,   318,   336,\n",
       "          340,   641,   863,  1749,  1816,  1850,  1890,  2141,  2563,\n",
       "         5633,  5796,  7195, 42541]),\n",
       " array([4, 2, 2, 2, 1, 2, 5, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows1_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_org_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 110)\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "print(X_trainvalid.shape)\n",
    "print(X_LRtrain.shape)\n",
    "print(9*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows1.shape # 75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
