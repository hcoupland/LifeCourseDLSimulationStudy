{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import timeit\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import sklearn.metrics as skm\n",
    "import importlib\n",
    "import fastai\n",
    "import tsai\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import shap\n",
    "importlib.reload(fastai)\n",
    "importlib.reload(tsai)\n",
    "import signatory\n",
    "import timeit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import Data_load_neat as Data_load\n",
    "import LM_cv_neat\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from tsai.all import *\n",
    "from tsai.data.validation import combine_split_data, get_splits\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.tslearner import TSClassifier\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import FastAIPruningCallback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, ReduceLROnPlateau\n",
    "from fastai.data.transforms import Categorize\n",
    "from fastai.losses import BCEWithLogitsLossFlat, FocalLoss, FocalLossFlat\n",
    "from fastai.metrics import accuracy, BrierScore, F1Score, RocAucBinary\n",
    "\n",
    "\n",
    "import Data_load_neat as Data_load\n",
    "import MLmodel_opt_learner_neat as MLmodel_opt_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in arguments from command line\n",
    "name = \"data_2real5newbigdet\"\n",
    "model_name=\"ResNet\"\n",
    "randnum_split=3\n",
    "epochs=8\n",
    "device = 1\n",
    "filepath=\"/home/DIDE/smishra/Simulations/\"\n",
    "folds=5\n",
    "randnum=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 9, 40) (100000, 40) (100000, 1)\n",
      "(100000,)\n",
      "Random state set:3, cuda used: True\n",
      "Counter({0.0: 93055, 1.0: 6945}) Counter({0.0: 74444, 1.0: 5556}) Counter({0.0: 18611, 1.0: 1389})\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_raw = Data_load.load_data(name=name,filepath=filepath)\n",
    "\n",
    "## Function to obtain the train/test split\n",
    "X_trainvalid, Y_trainvalid, X_test, Y_test, splits = Data_load.split_data(X=X_raw,Y=y_raw,randnum=randnum_split)\n",
    "\n",
    "## Now scale all the data for ease (can fix this later)\n",
    "X_scaled=Data_load.prep_data(X_raw,splits)\n",
    "\n",
    "X_trainvalid_s, X_test_s=X_scaled[splits[0]], X_scaled[splits[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_bin(pred, y_test):\n",
    "    # function to output accuracy, precision, recall, f1-score, AUC score and area under precision-recall curve and classification matrix\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    prec = precision_score(y_test,pred)\n",
    "    rec = recall_score( y_test,pred)\n",
    "    fone = f1_score(y_test,pred)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    prc= average_precision_score(y_test,pred)\n",
    "    print(\"{:<40} {:.6f}\".format(\"Accuracy:\", acc))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Precision:\", prec))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Recall:\", rec))\n",
    "    print(\"{:<40} {:.6f}\".format(\"F1 score:\", fone))\n",
    "    print(\"{:<40} {:.6f}\".format(\"AUC score:\", auc))\n",
    "\n",
    "    LR00 = np.sum(pred[(pred == y_test) & (y_test == 0)] + 1)\n",
    "    LR10 = np.sum(pred[(pred != y_test) & (y_test == 1)] + 1)\n",
    "    LR01 = np.sum(pred[(pred != y_test) & (y_test == 0)])\n",
    "    LR11 = np.sum(pred[(pred == y_test) & (y_test == 1)])\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 0 when actually 0:\", LR00))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 0 when actually 1:\", LR10))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 1 when actually 0:\", LR01))\n",
    "    print(\"{:<40} {:.6f}\".format(\"Predicted 1 when actually 1:\", LR11))\n",
    "    return acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LM_cv_neat\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                1.000000\n",
      "Precision:                               1.000000\n",
      "Recall:                                  1.000000\n",
      "F1 score:                                1.000000\n",
      "AUC score:                               1.000000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             0.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             1389.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.10222931e+01, -1.12651005e+01, -1.09118872e+01,\n",
       "        -1.08828640e+01, -1.08392677e+01, -1.08580055e+01,\n",
       "        -1.07901697e+01, -1.08152561e+01, -1.08252182e+01,\n",
       "        -1.08437624e+01, -1.08936977e+01, -1.08736610e+01,\n",
       "        -1.08684416e+01, -1.08235626e+01, -1.08113194e+01,\n",
       "        -1.08230591e+01, -1.08848696e+01, -1.08040190e+01,\n",
       "        -1.08010397e+01, -1.08326216e+01, -4.25344624e-05,\n",
       "         0.00000000e+00,  0.00000000e+00,  5.78321169e-06,\n",
       "        -4.51730120e-05,  5.31642718e-06, -4.24342979e-05,\n",
       "         5.90219952e-06,  4.92972367e-06,  4.87788157e-07,\n",
       "         0.00000000e+00, -2.19462936e-06,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.02286435e-06, -4.60505653e-05,\n",
       "         0.00000000e+00, -3.30966941e-07,  0.00000000e+00,\n",
       "         0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lr just for final row\n",
    "X_LRtrain=np.squeeze(X_trainvalid[:,-1,:])\n",
    "X_LRtest=np.squeeze(X_test[:,-1,:])\n",
    "\n",
    "\n",
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11 =LM_cv_neat.metrics_bin(LRpred, Y_test)\n",
    "\n",
    "LRmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sig_func(X_trainvalid, X_test, K):\n",
    "\n",
    "    num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "    num_samples_test = np.shape(X_test)[0]\n",
    "    sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "    X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "    X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "    \n",
    "\n",
    "    for i in range(0, num_samples):\n",
    "        xt = np.arange(0, num_timepoints)  ## time/age\n",
    "        xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = copy.copy(xtT)\n",
    "        for j in range(0, num_features):\n",
    "        \n",
    "            x1 = X_trainvalid[i, j, :]\n",
    "            x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "            path = torch.cat((path,x1T), 1)\n",
    "\n",
    "            #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "        path2 = path.unsqueeze(0)\n",
    "        X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "    for i in range(0, num_samples_test):\n",
    "        xt = np.arange(0, num_timepoints)  ## time/age\n",
    "        xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = copy.copy(xtT)\n",
    "        for j in range(0, num_features):\n",
    "        \n",
    "            x1 = X_test[i, j, :]\n",
    "            x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "            path = torch.cat((path,x1T), 1)\n",
    "\n",
    "            #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "        path2 = path.unsqueeze(0)\n",
    "        X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "    # function to reshape the data to flatten the time/feature dimensions into one\n",
    "    X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "    X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))\n",
    "\n",
    "    return X_LRtrainvalid, X_LRtest\n",
    "\n",
    "\n",
    "\n",
    "def SIGmodel_block(X_trainvalid, Y_trainvalid, X_test, Y_test, sig_depth, K, randnum=8):\n",
    "    # function to fit and analyse the logistic regression model\n",
    "    \n",
    "    # random seed\n",
    "    Data_load.random_seed(randnum)\n",
    "\n",
    "    # scale and one-hot the data\n",
    "    #X_scaled=Data_load.prep_data(X, splits)\n",
    "    #XStrainvalid=X_scaled[splits[0]]\n",
    "    #XStest=X_scaled[splits[1]]\n",
    "\n",
    "    # flatten the data\n",
    "    X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, sig_depth, K)\n",
    "\n",
    "    # fit the logistic regression model to the train data\n",
    "    start = timeit.default_timer()\n",
    "    LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "    stop = timeit.default_timer()\n",
    "    runtime=stop - start\n",
    "\n",
    "    # get model predictions on the test data\n",
    "    LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "    # get output metrics for test data\n",
    "    acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)\n",
    "    return runtime, acc, prec, rec, fone, auc, prc,  LR00, LR01, LR10, LR11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K=3\n",
    "\n",
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "num_samples_test = np.shape(X_test)[0]\n",
    "sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "\n",
    "X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = copy.copy(xtT)\n",
    "    for j in range(0, num_features):\n",
    "    \n",
    "        x1 = X_trainvalid[i, j, :]\n",
    "        x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = torch.cat((path,x1T), 1)\n",
    "\n",
    "        #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "for i in range(0, num_samples_test):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = copy.copy(xtT)\n",
    "    for j in range(0, num_features):\n",
    "    \n",
    "        x1 = X_test[i, j, :]\n",
    "        x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "        path = torch.cat((path,x1T), 1)\n",
    "\n",
    "        #path = torch.cat((xtT, x1T, x2T, x3T, x4T, x5T, x6T, x7T, x8T, x9T), 1)\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "# function to reshape the data to flatten the time/feature dimensions into one\n",
    "X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.929500\n",
      "Precision:                               0.376471\n",
      "Recall:                                  0.023038\n",
      "F1 score:                                0.043419\n",
      "AUC score:                               0.510095\n",
      "Predicted 0 when actually 0:             18558.000000\n",
      "Predicted 0 when actually 1:             1357.000000\n",
      "Predicted 1 when actually 0:             53.000000\n",
      "Predicted 1 when actually 1:             32.000000\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=K)\n",
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 1110)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LRtrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 9, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainvalid[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 22, 33)\n"
     ]
    }
   ],
   "source": [
    "def f(x, y, z):\n",
    "    return 2 * x**3 + 3 * y**2 - z\n",
    "x = np.linspace(1, 4, 11)\n",
    "y = np.linspace(4, 7, 22)\n",
    "z = np.linspace(7, 9, 33)\n",
    "xg, yg ,zg = np.meshgrid(x, y, z, indexing='ij', sparse=True)\n",
    "data = f(xg, yg, zg)\n",
    "\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125.80469388, 146.30069388])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interp = RegularGridInterpolator((x, y, z), data)\n",
    "\n",
    "pts = np.array([[2.1, 6.2, 8.3],\n",
    "                [3.3, 5.2, 7.1]])\n",
    "interp(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0.  0.  0.  0.5 1.  0.5 0.  0.  0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "x = range(1,10)\n",
    "y = range(1,41)\n",
    "xg, yg = np.meshgrid(x, y, indexing='ij', sparse=True)\n",
    "data = X_trainvalid[0,:,:]\n",
    "interp = RegularGridInterpolator((x, y), data)\n",
    "\n",
    "pts = np.array([[9, 1],\n",
    "                [9, 2],\n",
    "                [9, 3],\n",
    "                [9, 4],\n",
    "                [9, 5],\n",
    "                [9, 6],\n",
    "                [9, 7],\n",
    "                [9, 8],\n",
    "                [9, 9],\n",
    "                [9, 10],\n",
    "                [9, 11]])\n",
    "print(interp(pts))\n",
    "pts = np.array([[9, 1],\n",
    "                [9, 1.5],\n",
    "                [9, 2],\n",
    "                [9, 2.5],\n",
    "                [9, 3],\n",
    "                [9, 3.5],\n",
    "                [9, 4],\n",
    "                [9, 4.5],\n",
    "                [9, 5],\n",
    "                [9, 5.5],\n",
    "                [9, 6]])\n",
    "print(interp(pts))\n",
    "\n",
    "num_newfeatures = 100\n",
    "xn = np.linspace(1,9,9)\n",
    "yn= np.linspace(1,40,num_newfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "xng, yng = np.meshgrid(xn, yn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_features, num_timepoints = X_trainvalid.shape\n",
    "x = np.linspace(0,num_features-1,num_features)\n",
    "y= np.linspace(0,num_timepoints-1,num_timepoints)\n",
    "xg, yg = np.meshgrid(x, y, indexing='ij', sparse=True)\n",
    "data = X_trainvalid[0,:,:]\n",
    "interp = RegularGridInterpolator((x, y), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tv_sig= np.zeros(shape=(num_samples,num_features,num_newfeatures))\n",
    "#x = range(0,num_features)\n",
    "#y = range(0,num_timepoints)\n",
    "xn = np.linspace(0,num_features-1,num_features)\n",
    "yn= np.linspace(1,num_timepoints-1,num_newfeatures)\n",
    "xng, yng = np.meshgrid(xn, yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "0.0\n",
      "[1.0, 0.0]\n",
      "0.0\n",
      "[2.0, 0.0]\n",
      "0.0\n",
      "[3.0, 0.0]\n",
      "0.0\n",
      "[4.0, 0.0]\n",
      "0.0\n",
      "[5.0, 0.0]\n",
      "0.0\n",
      "[6.0, 0.0]\n",
      "0.0\n",
      "[7.0, 0.0]\n",
      "0.0\n",
      "[8.0, 0.0]\n",
      "0.0\n",
      "[9.0, 0.0]\n",
      "0.0\n",
      "[10.0, 0.0]\n",
      "0.0\n",
      "[11.0, 0.0]\n",
      "0.0\n",
      "[12.0, 0.0]\n",
      "0.0\n",
      "[13.0, 0.0]\n",
      "0.0\n",
      "[14.0, 0.0]\n",
      "0.0\n",
      "[15.0, 0.0]\n",
      "0.0\n",
      "[16.0, 0.0]\n",
      "0.0\n",
      "[17.0, 0.0]\n",
      "0.0\n",
      "[18.0, 0.0]\n",
      "0.0\n",
      "[19.0, 0.0]\n",
      "0.0\n",
      "[20.0, 0.0]\n",
      "0.0\n",
      "[21.0, 0.0]\n",
      "0.0\n",
      "[22.0, 0.0]\n",
      "0.0\n",
      "[23.0, 0.0]\n",
      "0.0\n",
      "[24.0, 0.0]\n",
      "0.0\n",
      "[25.0, 0.0]\n",
      "0.0\n",
      "[26.0, 0.0]\n",
      "0.0\n",
      "[27.0, 0.0]\n",
      "0.0\n",
      "[28.0, 0.0]\n",
      "0.0\n",
      "[29.0, 0.0]\n",
      "0.0\n",
      "[30.0, 0.0]\n",
      "0.0\n",
      "[31.0, 0.0]\n",
      "0.0\n",
      "[32.0, 0.0]\n",
      "0.0\n",
      "[33.0, 0.0]\n",
      "0.0\n",
      "[34.0, 0.0]\n",
      "0.0\n",
      "[35.0, 0.0]\n",
      "0.0\n",
      "[36.0, 0.0]\n",
      "0.0\n",
      "[37.0, 0.0]\n",
      "0.0\n",
      "[38.0, 0.0]\n",
      "0.0\n",
      "[39.0, 0.0]\n",
      "0.0\n",
      "[0.0, 1.0]\n",
      "1.0\n",
      "[1.0, 1.0]\n",
      "1.0\n",
      "[2.0, 1.0]\n",
      "1.0\n",
      "[3.0, 1.0]\n",
      "1.0\n",
      "[4.0, 1.0]\n",
      "1.0\n",
      "[5.0, 1.0]\n",
      "1.0\n",
      "[6.0, 1.0]\n",
      "1.0\n",
      "[7.0, 1.0]\n",
      "1.0\n",
      "[8.0, 1.0]\n",
      "1.0\n",
      "[9.0, 1.0]\n",
      "1.0\n",
      "[10.0, 1.0]\n",
      "1.0\n",
      "[11.0, 1.0]\n",
      "1.0\n",
      "[12.0, 1.0]\n",
      "1.0\n",
      "[13.0, 1.0]\n",
      "1.0\n",
      "[14.0, 1.0]\n",
      "1.0\n",
      "[15.0, 1.0]\n",
      "1.0\n",
      "[16.0, 1.0]\n",
      "1.0\n",
      "[17.0, 1.0]\n",
      "1.0\n",
      "[18.0, 1.0]\n",
      "1.0\n",
      "[19.0, 1.0]\n",
      "1.0\n",
      "[20.0, 1.0]\n",
      "1.0\n",
      "[21.0, 1.0]\n",
      "1.0\n",
      "[22.0, 1.0]\n",
      "1.0\n",
      "[23.0, 1.0]\n",
      "1.0\n",
      "[24.0, 1.0]\n",
      "1.0\n",
      "[25.0, 1.0]\n",
      "1.0\n",
      "[26.0, 1.0]\n",
      "1.0\n",
      "[27.0, 1.0]\n",
      "1.0\n",
      "[28.0, 1.0]\n",
      "1.0\n",
      "[29.0, 1.0]\n",
      "1.0\n",
      "[30.0, 1.0]\n",
      "1.0\n",
      "[31.0, 1.0]\n",
      "1.0\n",
      "[32.0, 1.0]\n",
      "1.0\n",
      "[33.0, 1.0]\n",
      "1.0\n",
      "[34.0, 1.0]\n",
      "1.0\n",
      "[35.0, 1.0]\n",
      "1.0\n",
      "[36.0, 1.0]\n",
      "1.0\n",
      "[37.0, 1.0]\n",
      "1.0\n",
      "[38.0, 1.0]\n",
      "1.0\n",
      "[39.0, 1.0]\n",
      "1.0\n",
      "[0.0, 2.0]\n",
      "2.0\n",
      "[1.0, 2.0]\n",
      "2.0\n",
      "[2.0, 2.0]\n",
      "2.0\n",
      "[3.0, 2.0]\n",
      "2.0\n",
      "[4.0, 2.0]\n",
      "2.0\n",
      "[5.0, 2.0]\n",
      "2.0\n",
      "[6.0, 2.0]\n",
      "2.0\n",
      "[7.0, 2.0]\n",
      "2.0\n",
      "[8.0, 2.0]\n",
      "2.0\n",
      "[9.0, 2.0]\n",
      "2.0\n",
      "[10.0, 2.0]\n",
      "2.0\n",
      "[11.0, 2.0]\n",
      "2.0\n",
      "[12.0, 2.0]\n",
      "2.0\n",
      "[13.0, 2.0]\n",
      "2.0\n",
      "[14.0, 2.0]\n",
      "2.0\n",
      "[15.0, 2.0]\n",
      "2.0\n",
      "[16.0, 2.0]\n",
      "2.0\n",
      "[17.0, 2.0]\n",
      "2.0\n",
      "[18.0, 2.0]\n",
      "2.0\n",
      "[19.0, 2.0]\n",
      "2.0\n",
      "[20.0, 2.0]\n",
      "2.0\n",
      "[21.0, 2.0]\n",
      "2.0\n",
      "[22.0, 2.0]\n",
      "2.0\n",
      "[23.0, 2.0]\n",
      "2.0\n",
      "[24.0, 2.0]\n",
      "2.0\n",
      "[25.0, 2.0]\n",
      "2.0\n",
      "[26.0, 2.0]\n",
      "2.0\n",
      "[27.0, 2.0]\n",
      "2.0\n",
      "[28.0, 2.0]\n",
      "2.0\n",
      "[29.0, 2.0]\n",
      "2.0\n",
      "[30.0, 2.0]\n",
      "2.0\n",
      "[31.0, 2.0]\n",
      "2.0\n",
      "[32.0, 2.0]\n",
      "2.0\n",
      "[33.0, 2.0]\n",
      "2.0\n",
      "[34.0, 2.0]\n",
      "2.0\n",
      "[35.0, 2.0]\n",
      "2.0\n",
      "[36.0, 2.0]\n",
      "2.0\n",
      "[37.0, 2.0]\n",
      "2.0\n",
      "[38.0, 2.0]\n",
      "2.0\n",
      "[39.0, 2.0]\n",
      "2.0\n",
      "[0.0, 3.0]\n",
      "3.0\n",
      "[1.0, 3.0]\n",
      "3.0\n",
      "[2.0, 3.0]\n",
      "3.0\n",
      "[3.0, 3.0]\n",
      "3.0\n",
      "[4.0, 3.0]\n",
      "3.0\n",
      "[5.0, 3.0]\n",
      "3.0\n",
      "[6.0, 3.0]\n",
      "3.0\n",
      "[7.0, 3.0]\n",
      "3.0\n",
      "[8.0, 3.0]\n",
      "3.0\n",
      "[9.0, 3.0]\n",
      "3.0\n",
      "[10.0, 3.0]\n",
      "3.0\n",
      "[11.0, 3.0]\n",
      "3.0\n",
      "[12.0, 3.0]\n",
      "3.0\n",
      "[13.0, 3.0]\n",
      "3.0\n",
      "[14.0, 3.0]\n",
      "3.0\n",
      "[15.0, 3.0]\n",
      "3.0\n",
      "[16.0, 3.0]\n",
      "3.0\n",
      "[17.0, 3.0]\n",
      "3.0\n",
      "[18.0, 3.0]\n",
      "3.0\n",
      "[19.0, 3.0]\n",
      "3.0\n",
      "[20.0, 3.0]\n",
      "3.0\n",
      "[21.0, 3.0]\n",
      "3.0\n",
      "[22.0, 3.0]\n",
      "3.0\n",
      "[23.0, 3.0]\n",
      "3.0\n",
      "[24.0, 3.0]\n",
      "3.0\n",
      "[25.0, 3.0]\n",
      "3.0\n",
      "[26.0, 3.0]\n",
      "3.0\n",
      "[27.0, 3.0]\n",
      "3.0\n",
      "[28.0, 3.0]\n",
      "3.0\n",
      "[29.0, 3.0]\n",
      "3.0\n",
      "[30.0, 3.0]\n",
      "3.0\n",
      "[31.0, 3.0]\n",
      "3.0\n",
      "[32.0, 3.0]\n",
      "3.0\n",
      "[33.0, 3.0]\n",
      "3.0\n",
      "[34.0, 3.0]\n",
      "3.0\n",
      "[35.0, 3.0]\n",
      "3.0\n",
      "[36.0, 3.0]\n",
      "3.0\n",
      "[37.0, 3.0]\n",
      "3.0\n",
      "[38.0, 3.0]\n",
      "3.0\n",
      "[39.0, 3.0]\n",
      "3.0\n",
      "[0.0, 4.0]\n",
      "4.0\n",
      "[1.0, 4.0]\n",
      "4.0\n",
      "[2.0, 4.0]\n",
      "4.0\n",
      "[3.0, 4.0]\n",
      "4.0\n",
      "[4.0, 4.0]\n",
      "4.0\n",
      "[5.0, 4.0]\n",
      "4.0\n",
      "[6.0, 4.0]\n",
      "4.0\n",
      "[7.0, 4.0]\n",
      "4.0\n",
      "[8.0, 4.0]\n",
      "4.0\n",
      "[9.0, 4.0]\n",
      "4.0\n",
      "[10.0, 4.0]\n",
      "4.0\n",
      "[11.0, 4.0]\n",
      "4.0\n",
      "[12.0, 4.0]\n",
      "4.0\n",
      "[13.0, 4.0]\n",
      "4.0\n",
      "[14.0, 4.0]\n",
      "4.0\n",
      "[15.0, 4.0]\n",
      "4.0\n",
      "[16.0, 4.0]\n",
      "4.0\n",
      "[17.0, 4.0]\n",
      "4.0\n",
      "[18.0, 4.0]\n",
      "4.0\n",
      "[19.0, 4.0]\n",
      "4.0\n",
      "[20.0, 4.0]\n",
      "4.0\n",
      "[21.0, 4.0]\n",
      "4.0\n",
      "[22.0, 4.0]\n",
      "4.0\n",
      "[23.0, 4.0]\n",
      "4.0\n",
      "[24.0, 4.0]\n",
      "4.0\n",
      "[25.0, 4.0]\n",
      "4.0\n",
      "[26.0, 4.0]\n",
      "4.0\n",
      "[27.0, 4.0]\n",
      "4.0\n",
      "[28.0, 4.0]\n",
      "4.0\n",
      "[29.0, 4.0]\n",
      "4.0\n",
      "[30.0, 4.0]\n",
      "4.0\n",
      "[31.0, 4.0]\n",
      "4.0\n",
      "[32.0, 4.0]\n",
      "4.0\n",
      "[33.0, 4.0]\n",
      "4.0\n",
      "[34.0, 4.0]\n",
      "4.0\n",
      "[35.0, 4.0]\n",
      "4.0\n",
      "[36.0, 4.0]\n",
      "4.0\n",
      "[37.0, 4.0]\n",
      "4.0\n",
      "[38.0, 4.0]\n",
      "4.0\n",
      "[39.0, 4.0]\n",
      "4.0\n",
      "[0.0, 5.0]\n",
      "5.0\n",
      "[1.0, 5.0]\n",
      "5.0\n",
      "[2.0, 5.0]\n",
      "5.0\n",
      "[3.0, 5.0]\n",
      "5.0\n",
      "[4.0, 5.0]\n",
      "5.0\n",
      "[5.0, 5.0]\n",
      "5.0\n",
      "[6.0, 5.0]\n",
      "5.0\n",
      "[7.0, 5.0]\n",
      "5.0\n",
      "[8.0, 5.0]\n",
      "5.0\n",
      "[9.0, 5.0]\n",
      "5.0\n",
      "[10.0, 5.0]\n",
      "5.0\n",
      "[11.0, 5.0]\n",
      "5.0\n",
      "[12.0, 5.0]\n",
      "5.0\n",
      "[13.0, 5.0]\n",
      "5.0\n",
      "[14.0, 5.0]\n",
      "5.0\n",
      "[15.0, 5.0]\n",
      "5.0\n",
      "[16.0, 5.0]\n",
      "5.0\n",
      "[17.0, 5.0]\n",
      "5.0\n",
      "[18.0, 5.0]\n",
      "5.0\n",
      "[19.0, 5.0]\n",
      "5.0\n",
      "[20.0, 5.0]\n",
      "5.0\n",
      "[21.0, 5.0]\n",
      "5.0\n",
      "[22.0, 5.0]\n",
      "5.0\n",
      "[23.0, 5.0]\n",
      "5.0\n",
      "[24.0, 5.0]\n",
      "5.0\n",
      "[25.0, 5.0]\n",
      "5.0\n",
      "[26.0, 5.0]\n",
      "5.0\n",
      "[27.0, 5.0]\n",
      "5.0\n",
      "[28.0, 5.0]\n",
      "5.0\n",
      "[29.0, 5.0]\n",
      "5.0\n",
      "[30.0, 5.0]\n",
      "5.0\n",
      "[31.0, 5.0]\n",
      "5.0\n",
      "[32.0, 5.0]\n",
      "5.0\n",
      "[33.0, 5.0]\n",
      "5.0\n",
      "[34.0, 5.0]\n",
      "5.0\n",
      "[35.0, 5.0]\n",
      "5.0\n",
      "[36.0, 5.0]\n",
      "5.0\n",
      "[37.0, 5.0]\n",
      "5.0\n",
      "[38.0, 5.0]\n",
      "5.0\n",
      "[39.0, 5.0]\n",
      "5.0\n",
      "[0.0, 6.0]\n",
      "6.0\n",
      "[1.0, 6.0]\n",
      "6.0\n",
      "[2.0, 6.0]\n",
      "6.0\n",
      "[3.0, 6.0]\n",
      "6.0\n",
      "[4.0, 6.0]\n",
      "6.0\n",
      "[5.0, 6.0]\n",
      "6.0\n",
      "[6.0, 6.0]\n",
      "6.0\n",
      "[7.0, 6.0]\n",
      "6.0\n",
      "[8.0, 6.0]\n",
      "6.0\n",
      "[9.0, 6.0]\n",
      "6.0\n",
      "[10.0, 6.0]\n",
      "6.0\n",
      "[11.0, 6.0]\n",
      "6.0\n",
      "[12.0, 6.0]\n",
      "6.0\n",
      "[13.0, 6.0]\n",
      "6.0\n",
      "[14.0, 6.0]\n",
      "6.0\n",
      "[15.0, 6.0]\n",
      "6.0\n",
      "[16.0, 6.0]\n",
      "6.0\n",
      "[17.0, 6.0]\n",
      "6.0\n",
      "[18.0, 6.0]\n",
      "6.0\n",
      "[19.0, 6.0]\n",
      "6.0\n",
      "[20.0, 6.0]\n",
      "6.0\n",
      "[21.0, 6.0]\n",
      "6.0\n",
      "[22.0, 6.0]\n",
      "6.0\n",
      "[23.0, 6.0]\n",
      "6.0\n",
      "[24.0, 6.0]\n",
      "6.0\n",
      "[25.0, 6.0]\n",
      "6.0\n",
      "[26.0, 6.0]\n",
      "6.0\n",
      "[27.0, 6.0]\n",
      "6.0\n",
      "[28.0, 6.0]\n",
      "6.0\n",
      "[29.0, 6.0]\n",
      "6.0\n",
      "[30.0, 6.0]\n",
      "6.0\n",
      "[31.0, 6.0]\n",
      "6.0\n",
      "[32.0, 6.0]\n",
      "6.0\n",
      "[33.0, 6.0]\n",
      "6.0\n",
      "[34.0, 6.0]\n",
      "6.0\n",
      "[35.0, 6.0]\n",
      "6.0\n",
      "[36.0, 6.0]\n",
      "6.0\n",
      "[37.0, 6.0]\n",
      "6.0\n",
      "[38.0, 6.0]\n",
      "6.0\n",
      "[39.0, 6.0]\n",
      "6.0\n",
      "[0.0, 7.0]\n",
      "7.0\n",
      "[1.0, 7.0]\n",
      "7.0\n",
      "[2.0, 7.0]\n",
      "7.0\n",
      "[3.0, 7.0]\n",
      "7.0\n",
      "[4.0, 7.0]\n",
      "7.0\n",
      "[5.0, 7.0]\n",
      "7.0\n",
      "[6.0, 7.0]\n",
      "7.0\n",
      "[7.0, 7.0]\n",
      "7.0\n",
      "[8.0, 7.0]\n",
      "7.0\n",
      "[9.0, 7.0]\n",
      "7.0\n",
      "[10.0, 7.0]\n",
      "7.0\n",
      "[11.0, 7.0]\n",
      "7.0\n",
      "[12.0, 7.0]\n",
      "7.0\n",
      "[13.0, 7.0]\n",
      "7.0\n",
      "[14.0, 7.0]\n",
      "7.0\n",
      "[15.0, 7.0]\n",
      "7.0\n",
      "[16.0, 7.0]\n",
      "7.0\n",
      "[17.0, 7.0]\n",
      "7.0\n",
      "[18.0, 7.0]\n",
      "7.0\n",
      "[19.0, 7.0]\n",
      "7.0\n",
      "[20.0, 7.0]\n",
      "7.0\n",
      "[21.0, 7.0]\n",
      "7.0\n",
      "[22.0, 7.0]\n",
      "7.0\n",
      "[23.0, 7.0]\n",
      "7.0\n",
      "[24.0, 7.0]\n",
      "7.0\n",
      "[25.0, 7.0]\n",
      "7.0\n",
      "[26.0, 7.0]\n",
      "7.0\n",
      "[27.0, 7.0]\n",
      "7.0\n",
      "[28.0, 7.0]\n",
      "7.0\n",
      "[29.0, 7.0]\n",
      "7.0\n",
      "[30.0, 7.0]\n",
      "7.0\n",
      "[31.0, 7.0]\n",
      "7.0\n",
      "[32.0, 7.0]\n",
      "7.0\n",
      "[33.0, 7.0]\n",
      "7.0\n",
      "[34.0, 7.0]\n",
      "7.0\n",
      "[35.0, 7.0]\n",
      "7.0\n",
      "[36.0, 7.0]\n",
      "7.0\n",
      "[37.0, 7.0]\n",
      "7.0\n",
      "[38.0, 7.0]\n",
      "7.0\n",
      "[39.0, 7.0]\n",
      "7.0\n",
      "[0.0, 8.0]\n",
      "8.0\n",
      "[1.0, 8.0]\n",
      "8.0\n",
      "[2.0, 8.0]\n",
      "8.0\n",
      "[3.0, 8.0]\n",
      "8.0\n",
      "[4.0, 8.0]\n",
      "8.0\n",
      "[5.0, 8.0]\n",
      "8.0\n",
      "[6.0, 8.0]\n",
      "8.0\n",
      "[7.0, 8.0]\n",
      "8.0\n",
      "[8.0, 8.0]\n",
      "8.0\n",
      "[9.0, 8.0]\n",
      "8.0\n",
      "[10.0, 8.0]\n",
      "8.0\n",
      "[11.0, 8.0]\n",
      "8.0\n",
      "[12.0, 8.0]\n",
      "8.0\n",
      "[13.0, 8.0]\n",
      "8.0\n",
      "[14.0, 8.0]\n",
      "8.0\n",
      "[15.0, 8.0]\n",
      "8.0\n",
      "[16.0, 8.0]\n",
      "8.0\n",
      "[17.0, 8.0]\n",
      "8.0\n",
      "[18.0, 8.0]\n",
      "8.0\n",
      "[19.0, 8.0]\n",
      "8.0\n",
      "[20.0, 8.0]\n",
      "8.0\n",
      "[21.0, 8.0]\n",
      "8.0\n",
      "[22.0, 8.0]\n",
      "8.0\n",
      "[23.0, 8.0]\n",
      "8.0\n",
      "[24.0, 8.0]\n",
      "8.0\n",
      "[25.0, 8.0]\n",
      "8.0\n",
      "[26.0, 8.0]\n",
      "8.0\n",
      "[27.0, 8.0]\n",
      "8.0\n",
      "[28.0, 8.0]\n",
      "8.0\n",
      "[29.0, 8.0]\n",
      "8.0\n",
      "[30.0, 8.0]\n",
      "8.0\n",
      "[31.0, 8.0]\n",
      "8.0\n",
      "[32.0, 8.0]\n",
      "8.0\n",
      "[33.0, 8.0]\n",
      "8.0\n",
      "[34.0, 8.0]\n",
      "8.0\n",
      "[35.0, 8.0]\n",
      "8.0\n",
      "[36.0, 8.0]\n",
      "8.0\n",
      "[37.0, 8.0]\n",
      "8.0\n",
      "[38.0, 8.0]\n",
      "8.0\n",
      "[39.0, 8.0]\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "for j in x:\n",
    "    for k in y:\n",
    "        print([k,j])\n",
    "        print(xng[int(k),int(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,num_samples):\n",
    "    data = X_trainvalid[i,:,:]\n",
    "    interp = RegularGridInterpolator((x, y), data)\n",
    "    for j in xn:\n",
    "        for k in yn:\n",
    "            X_tv_sig[int(i),int(j),int(k)] = interp([xng[int(k),int(j)],yng[int(k),int(j)]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "data = X_trainvalid[i,:,:]\n",
    "interp = RegularGridInterpolator((x, y), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.38383838,  1.76767677,  2.15151515,  2.53535354,\n",
       "        2.91919192,  3.3030303 ,  3.68686869,  4.07070707,  4.45454545,\n",
       "        4.83838384,  5.22222222,  5.60606061,  5.98989899,  6.37373737,\n",
       "        6.75757576,  7.14141414,  7.52525253,  7.90909091,  8.29292929,\n",
       "        8.67676768,  9.06060606,  9.44444444,  9.82828283, 10.21212121,\n",
       "       10.5959596 , 10.97979798, 11.36363636, 11.74747475, 12.13131313,\n",
       "       12.51515152, 12.8989899 , 13.28282828, 13.66666667, 14.05050505,\n",
       "       14.43434343, 14.81818182, 15.2020202 , 15.58585859, 15.96969697,\n",
       "       16.35353535, 16.73737374, 17.12121212, 17.50505051, 17.88888889,\n",
       "       18.27272727, 18.65656566, 19.04040404, 19.42424242, 19.80808081,\n",
       "       20.19191919, 20.57575758, 20.95959596, 21.34343434, 21.72727273,\n",
       "       22.11111111, 22.49494949, 22.87878788, 23.26262626, 23.64646465,\n",
       "       24.03030303, 24.41414141, 24.7979798 , 25.18181818, 25.56565657,\n",
       "       25.94949495, 26.33333333, 26.71717172, 27.1010101 , 27.48484848,\n",
       "       27.86868687, 28.25252525, 28.63636364, 29.02020202, 29.4040404 ,\n",
       "       29.78787879, 30.17171717, 30.55555556, 30.93939394, 31.32323232,\n",
       "       31.70707071, 32.09090909, 32.47474747, 32.85858586, 33.24242424,\n",
       "       33.62626263, 34.01010101, 34.39393939, 34.77777778, 35.16161616,\n",
       "       35.54545455, 35.92929293, 36.31313131, 36.6969697 , 37.08080808,\n",
       "       37.46464646, 37.84848485, 38.23232323, 38.61616162, 39.        ])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "numt_samples, numt_features, numt_timepoints = X_test.shape\n",
    "X_t_sig= np.zeros(shape=(numt_samples,num_features,num_newfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,numt_samples):\n",
    "    data = X_test[i,:,:]\n",
    "    interp = RegularGridInterpolator((x, y), data)\n",
    "    for j in x:\n",
    "        for k in y:\n",
    "            X_t_sig[int(i),int(j),int(k)] = interp([xng[int(k),int(j)],yng[int(k),int(j)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.930550\n",
      "Precision:                               0.000000\n",
      "Recall:                                  0.000000\n",
      "F1 score:                                0.000000\n",
      "AUC score:                               0.500000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             1389.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             0.000000\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_tv_sig, X_t_sig, K=K)\n",
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.38383838, 0.76767677, 0.84848485, 0.46464646,\n",
       "       0.08080808, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06060606, 0.44444444, 0.82828283, 0.78787879,\n",
       "       0.4040404 , 0.02020202, 0.        , 0.        , 0.13131313,\n",
       "       0.51515152, 0.8989899 , 0.71717172, 0.33333333, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tv_sig[0,8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainvalid[0,8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53731664 7.19942405]\n"
     ]
    }
   ],
   "source": [
    "class_weights=sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=[0,1], y=Y_trainvalid)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.930550\n",
      "Precision:                               0.000000\n",
      "Recall:                                  0.000000\n",
      "F1 score:                                0.000000\n",
      "AUC score:                               0.500000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             1389.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid[:,range(7,9),:], X_test[:,range(7,9),:], K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.930550\n",
      "Precision:                               0.000000\n",
      "Recall:                                  0.000000\n",
      "F1 score:                                0.000000\n",
      "AUC score:                               0.500000\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             1389.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain, X_LRtest = LM_cv_neat.LM_func(X_trainvalid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 64981)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "poly = PolynomialFeatures(2, interaction_only=True)\n",
    "Xpoly=poly.fit_transform(X_LRtrain)\n",
    "\n",
    "Xpoly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 64981)\n",
      "Accuracy:                                0.992200\n",
      "Precision:                               1.000000\n",
      "Recall:                                  0.887689\n",
      "F1 score:                                0.940503\n",
      "AUC score:                               0.943844\n",
      "Predicted 0 when actually 0:             18611.000000\n",
      "Predicted 0 when actually 1:             156.000000\n",
      "Predicted 1 when actually 0:             0.000000\n",
      "Predicted 1 when actually 1:             1233.000000\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\",random_state=randnum).fit(Xpoly, Y_trainvalid)\n",
    "\n",
    "X_test_poly=poly.transform(X_LRtest)\n",
    "print(X_test_poly.shape)\n",
    "\n",
    "   # get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_test_poly)\n",
    "\n",
    "   # get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11 =metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m selector \u001b[39m=\u001b[39m RFE(LogisticRegression(), \u001b[39m25\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m final_clf \u001b[39m=\u001b[39m SVC()\n\u001b[1;32m      3\u001b[0m rfe_model \u001b[39m=\u001b[39m Pipeline([(\u001b[39m\"\u001b[39m\u001b[39mrfe\u001b[39m\u001b[39m\"\u001b[39m,selector),(\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m,final_clf)])\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "selector = RFE(LogisticRegression(), 25)\n",
    "final_clf = SVC()\n",
    "rfe_model = Pipeline([(\"rfe\",selector),('model',final_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_model.fit(Xpoly,Y_trainvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "Y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.929250\n",
      "Precision:                               0.379630\n",
      "Recall:                                  0.029518\n",
      "F1 score:                                0.054776\n",
      "AUC score:                               0.512959\n",
      "Predicted 0 when actually 0:             18544.000000\n",
      "Predicted 0 when actually 1:             1348.000000\n",
      "Predicted 1 when actually 0:             67.000000\n",
      "Predicted 1 when actually 1:             41.000000\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "\n",
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid[:,range(7,9),:], X_test[:,range(7,9),:], K=K)\n",
    "\n",
    "\n",
    "# fit the logistic regression model to the train data\n",
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrain, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3 \n",
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "num_features=1\n",
    "num_samples_test = np.shape(X_test)[0]\n",
    "sig_length=int(((num_features+1)**(K+1)-1)/num_features ) -1\n",
    "X_sigtrainvalid = np.zeros(shape=[num_samples, 1, sig_length], dtype=float)\n",
    "X_sigtest = np.zeros(shape=[num_samples_test, 1, sig_length], dtype=float)\n",
    "\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "\n",
    "    x1 = X_trainvalid[i, 8, :]\n",
    "    x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = torch.cat((xtT,x1T), 1)\n",
    "\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtrainvalid[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "for i in range(0, num_samples_test):\n",
    "    xt = np.arange(0, num_timepoints)  ## time/age\n",
    "    xtT = torch.tensor(xt.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    \n",
    "    x1 = X_test[i, 8, :]\n",
    "    x1T = torch.tensor(x1.reshape(num_timepoints, 1), dtype=torch.float)\n",
    "    path = torch.cat((xtT,x1T), 1)\n",
    "\n",
    "    path2 = path.unsqueeze(0)\n",
    "    X_sigtest[i, 0, :] = signatory.signature(path2, K).numpy()\n",
    "\n",
    "# function to reshape the data to flatten the time/feature dimensions into one\n",
    "X_LRtrainvalid=np.reshape(X_sigtrainvalid,(num_samples,sig_length))\n",
    "X_LRtest=np.reshape(X_sigtest,(num_samples_test,sig_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:                                0.929400\n",
      "Precision:                               0.394495\n",
      "Recall:                                  0.030958\n",
      "F1 score:                                0.057410\n",
      "AUC score:                               0.513706\n",
      "Predicted 0 when actually 0:             18545.000000\n",
      "Predicted 0 when actually 1:             1346.000000\n",
      "Predicted 1 when actually 0:             66.000000\n",
      "Predicted 1 when actually 1:             43.000000\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(penalty=\"l2\", solver=\"saga\",random_state=randnum,multi_class='ovr',class_weight=class_weights).fit(X_LRtrainvalid, Y_trainvalid)\n",
    "\n",
    "# get model predictions on the test data\n",
    "LRpred = LRmodel.predict(X_LRtest)\n",
    "\n",
    "# get output metrics for test data\n",
    "acc, prec, rec, fone, auc, prc, LR00, LR01, LR10, LR11= metrics_bin(LRpred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,\n",
       "         67,  68,  69,  70,  72,  73,  75,  76,  77,  78,  79,  80,  81,\n",
       "         82,  83,  86,  87,  88,  91,  92,  93,  95,  96,  99, 100, 102,\n",
       "        115, 117, 461]),\n",
       " array([26948,  4272,  1688,   848,   510,   347,   245,   189,   155,\n",
       "          139,   104,    91,    70,    70,    60,    43,    41,    28,\n",
       "           28,    24,    27,    23,    17,    11,    14,    11,    10,\n",
       "            8,    13,    13,     6,     8,    13,    10,    10,     3,\n",
       "            4,     5,     7,    10,     5,     7,     4,    13,     8,\n",
       "           11,     3,     6,     5,     7,     8,    11,     5,     5,\n",
       "            4,     4,     3,     7,     4,     4,     3,     3,     2,\n",
       "            6,     3,     1,     2,     4,     2,     1,     1,     1,\n",
       "            1,     1,     3,     2,     2,     1,     2,     2,     1,\n",
       "            2,     1,     2,     1,     1,     1,     1,     2,     1,\n",
       "            1,     1,     1,     1]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rowsmin, unique_rowsmin_cnt = np.unique(X_LRtrainvalid, axis=0,return_counts=True)\n",
    "np.unique(unique_rowsmin_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  45,  49,  50,  51,  52,\n",
       "         54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,\n",
       "         69,  70,  72,  75,  83,  96, 461]),\n",
       " array([59600,  3370,   935,   287,   109,   119,   112,   106,    72,\n",
       "           82,    64,    48,    30,    21,    10,     6,     6,     1,\n",
       "            3,     1,     2,     1,     1,     2,     1,     4,     1,\n",
       "            2,     2,     3,     3,     3,     1,     1,     1,     4,\n",
       "            1,     1,     2,     1,     1,     1,     1,     1,     1,\n",
       "            1]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rowsmain, unique_rowsmain_cnt = np.unique(X_trainvalid[:,8,:], axis=0,return_counts=True)\n",
    "np.unique(unique_rowsmain_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.69792269e-07,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -7.28510167e-07,  2.65038999e-06,  5.56744219e-06]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [39.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LRtrain[0:10,0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other bits of proving why the signature is bad for this type of data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I think I'll start with showing it can be the same for different time series*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 110)\n"
     ]
    }
   ],
   "source": [
    "X_LRtrain, X_LRtest = Sig_func(X_trainvalid, X_test, K=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain1, X_LRtest1 = Sig_func(X_trainvalid, X_test, K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 10)\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "print(X_trainvalid.shape)\n",
    "print(X_LRtrain1.shape)\n",
    "print(9*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows1, unique_rows1_cnt = np.unique(X_LRtrain1, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows2, unique_rows2_cnt = np.unique(X_LRtrain, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LRtrain3, X_LRtest3 = Sig_func(X_trainvalid, X_test, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1110)\n"
     ]
    }
   ],
   "source": [
    "print(X_LRtrain3.shape) ## much bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows3, unique_rows3_cnt = np.unique(X_LRtrain3, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79998, 1110)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows3.shape ## almost all unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3]), array([79997,     1]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows3_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54788, 110)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  45,  46,  47,  49,  50,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  65,  66,  68,  70,  72,  74,\n",
       "         76,  78,  85, 106]),\n",
       " array([46726,  4355,  1442,   665,   419,   274,   172,   133,   105,\n",
       "           70,    67,    39,    26,    31,    22,    24,    18,    14,\n",
       "            7,    12,    10,     6,     8,    10,     6,     6,     2,\n",
       "            5,     5,     7,     6,     7,     6,     4,     4,     4,\n",
       "            2,     3,     5,     4,     3,     5,     6,     4,     4,\n",
       "            1,     3,     2,     1,     3,     2,     1,     1,     1,\n",
       "            1,     3,     1,     1,     2,     1,     2,     1,     2,\n",
       "            1,     1,     1,     1,     1,     1]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows2_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_org, unique_rows_org_cnt = np.unique(X_trainvalid, axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples,num_features,num_timepoints = np.shape(X_trainvalid)\n",
    "unique_rows_org, unique_rows_org_cnt = np.unique(X_trainvalid.reshape(num_samples,num_features*num_timepoints), axis=0,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 360)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_org.shape ## all unique 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    1,     2,     3,     4,     6,     8,     9,    10,    11,\n",
       "           12,    13,    14,    15,    17,    20,    21,    31,    32,\n",
       "           35,    36,    37,    49,    72,    75,    82,    87,    88,\n",
       "           97,    99,   102,   108,   113,   142,   211,   217,   220,\n",
       "          240,   243,   253,   265,   269,   270,   309,   318,   336,\n",
       "          340,   641,   863,  1749,  1816,  1850,  1890,  2141,  2563,\n",
       "         5633,  5796,  7195, 42541]),\n",
       " array([4, 2, 2, 2, 1, 2, 5, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(unique_rows1_cnt,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_org_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 9, 40)\n",
      "(80000, 110)\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "print(X_trainvalid.shape)\n",
    "print(X_LRtrain.shape)\n",
    "print(9*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows1.shape # 75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
